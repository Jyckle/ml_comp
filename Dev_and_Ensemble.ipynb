{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition Development Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import unicodedata as ud\n",
    "import csv\n",
    "import random\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the vocab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab():\n",
    "    with open('vocab.csv') as file:\n",
    "        reader = csv.reader(file)\n",
    "        vocab = list(reader)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep training data for N Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(filename, N):\n",
    "    pre_string = \"<s>\"\n",
    "    post_string = \"</s>\"\n",
    "    train_dat = []\n",
    "        \n",
    "    with open(filename, encoding=\"utf8\") as file:\n",
    "        for line in file:\n",
    "            line = ud.normalize(\"NFC\",line)\n",
    "            line = re.sub('[,.?\"“”]','',line)\n",
    "            line = re.sub('\\s+',' ',line)\n",
    "            split_line = line.strip().split()\n",
    "            for gram in range(1,N):\n",
    "                split_line.insert(0,pre_string)\n",
    "                split_line.append(post_string)\n",
    "            train_dat.append(split_line)\n",
    "    \n",
    "    return train_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a test example from a training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_example(training_line,word):\n",
    "    if \" \" + word[0] + \" \" in training_line:\n",
    "        new_str = ' {'+word[0]+\"|\"+word[1] + '} '\n",
    "        test_line = re.sub(\" \" + word[0] + \" \",new_str, training_line,1)\n",
    "        test_line = re.sub(\"<s>\",\"\",test_line)\n",
    "        test_line = re.sub(\"</s>\",\"\",test_line)\n",
    "        prob = 1\n",
    "        return test_line.strip(),prob\n",
    "    elif \" \" + word[1] + \" \" in training_line:\n",
    "        new_str = ' {'+word[0]+\"|\"+word[1] + '} '\n",
    "        test_line = re.sub(\" \" + word[1] + \" \",new_str, training_line,1)\n",
    "        test_line = re.sub(\"<s>\",\"\",test_line)\n",
    "        test_line = re.sub(\"</s>\",\"\",test_line)\n",
    "        prob = 0\n",
    "        return test_line.strip(),prob\n",
    "    else:\n",
    "        print(\"Error, word not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine which vocab word corresponds to location in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_vocab(index):\n",
    "    if index < 24200:\n",
    "        return 0, 24200\n",
    "    elif index < 48400:\n",
    "        return 1, 24200\n",
    "    elif index < 51290:\n",
    "        return 2, 2890\n",
    "    elif index < 75490:\n",
    "        return 3, 24200\n",
    "    elif index < 99690:\n",
    "        return 4, 24200\n",
    "    elif index < 123890:\n",
    "        return 5, 24200\n",
    "    elif index < 131159:\n",
    "        return 6, 7269\n",
    "    elif index < 155359:\n",
    "        return 7, 24200\n",
    "    elif index < 179559:\n",
    "        return 8, 24200\n",
    "    elif index < 203759:\n",
    "        return 9, 24200\n",
    "    elif index < 227959:\n",
    "        return 10, 24200\n",
    "    elif index < 252159:\n",
    "        return 11, 24200\n",
    "    elif index < 258227:\n",
    "        return 12, 6068\n",
    "    elif index < 282427:\n",
    "        return 13, 24200\n",
    "    elif index < 306627:\n",
    "        return 14, 24200\n",
    "    elif index < 310023:\n",
    "        return 15, 3396\n",
    "    elif index < 334223:\n",
    "        return 16, 24200\n",
    "    elif index < 358423:\n",
    "        return 17, 24200\n",
    "    elif index < 382623:\n",
    "        return 18, 24200\n",
    "    elif index < 406823:\n",
    "        return 19, 24200\n",
    "    elif index < 418928:\n",
    "        return 20, 12105\n",
    "    elif index < 430425:\n",
    "        return 21, 11497\n",
    "    elif index < 446988:\n",
    "        return 22, 16563\n",
    "    elif index < 452037:\n",
    "        return 23, 5049\n",
    "    elif index < 456571:\n",
    "        return 24, 4534"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and development\n",
    "#### Dev is saved to file, along with dev answers, new training array is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_split(train_array, percent_split, vocab_df, dev_filename, answers_filename):\n",
    "    dev_file = open(dev_filename,'w',encoding='utf8')\n",
    "    dev_answers = open(answers_filename,'w',encoding='utf8')\n",
    "    dev_answers.write(\"Id,Expected\\n\")\n",
    "    new_train = []\n",
    "\n",
    "    count = 1\n",
    "    vocab_word = 0\n",
    "    for index,training_line in enumerate(train_array):\n",
    "        vocab_word, vocab_count = which_vocab(index)  \n",
    "        if random.random() < percent_split/100:\n",
    "            test_line, prob = create_test_example(\" \".join(training_line),vocab_df[vocab_word])\n",
    "            dev_answers.write(str(count) + \",\" + str(prob) + \"\\n\")\n",
    "            dev_file.write(test_line + \"\\n\")\n",
    "            count += 1\n",
    "        else:\n",
    "            new_train.append(training_line)\n",
    "        \n",
    "    dev_file.close()\n",
    "    dev_answers.close()\n",
    "    \n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually create the dictionary with all n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, N):\n",
    "    model = {}\n",
    "    for line in train_data:\n",
    "        for each_N in range(1,N+1):\n",
    "            #for each line, generate all ngrams\n",
    "            for index in range(0,len(line)-each_N):\n",
    "                ngram = line[index]\n",
    "                for n_forward in range(1,each_N):\n",
    "                    ngram += ' ' + line[index+n_forward]\n",
    "                if ngram in model:\n",
    "                    model[ngram] += 1\n",
    "                else:\n",
    "                    model[ngram] = 1\n",
    "    return model            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract N-gram choices from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(filename, N):\n",
    "    choices=[]\n",
    "    reg_exp_str = ' \\{(.*)\\|(.*)\\} '\n",
    "    pre_string = ''\n",
    "    post_string = ''\n",
    "    for gram in range(1,N):\n",
    "        pre_string += '<s> '\n",
    "        post_string += ' </s>'\n",
    "        if gram % 2 == 0:\n",
    "            reg_exp_str = reg_exp_str + '([^ ]+) '\n",
    "        else:\n",
    "            reg_exp_str = ' ([^ ]+)' + reg_exp_str\n",
    "    \n",
    "    reg_exp = re.compile(reg_exp_str)\n",
    "    with open(filename, encoding=\"utf8\") as file:\n",
    "        for row in file:\n",
    "            row = ud.normalize(\"NFC\",row)\n",
    "            row = re.sub('[,.?\"“”]','',row)\n",
    "            row = re.sub('\\s+',' ',row)\n",
    "            row = pre_string + row.strip() + post_string\n",
    "            #extract options\n",
    "            match = reg_exp.search(row)\n",
    "            if match:\n",
    "                if N%2 ==0:\n",
    "                    midpoint = math.ceil((N+2)/2)\n",
    "                else:\n",
    "                    midpoint = math.ceil(N/2)\n",
    "                choice_1 = match.group(midpoint)\n",
    "                #print(choice_1)\n",
    "                choice_2 = match.group(midpoint+1)\n",
    "                #print(choice_2)\n",
    "                for match_group in range(midpoint+2,N+2):\n",
    "                    choice_1 += ' ' + match.group(match_group)\n",
    "                    choice_2 += ' ' + match.group(match_group)\n",
    "                for match_group in range(midpoint-1,0,-1):\n",
    "                    choice_1 = match.group(match_group) + ' ' + choice_1\n",
    "                    choice_2 = match.group(match_group) + ' ' + choice_2\n",
    "                choice = (choice_1, choice_2)\n",
    "            else:\n",
    "                print('error, no value')\n",
    "                choice = 'error'\n",
    "            choices.append(choice)\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices =prepare_test_data('test.txt',3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability function to determine likelihood of option_1 and option_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backoff_probability(option_1,option_2,model):\n",
    "    if option_1 in model:\n",
    "        count_1 = model[option_1]\n",
    "    else:\n",
    "        count_1 = 0\n",
    "        \n",
    "    if option_2 in model:\n",
    "        count_2 = model[option_2]\n",
    "    else:\n",
    "        count_2 = 0\n",
    "    \n",
    "    if abs(count_1 - count_2) < 2:\n",
    "    #if count_1 < 2 and count_2 < 2:\n",
    "    #if count_1 == 0 and count_2 == 0:\n",
    "        split_1 = option_1.split()\n",
    "        split_2 = option_2.split()\n",
    "        if len(split_1) > 1 and len(split_2) > 1:\n",
    "            if len(split_1) % 2 ==0:\n",
    "                split_1.pop(0)\n",
    "                split_2.pop(0)\n",
    "            else:\n",
    "                split_1.pop()\n",
    "                split_2.pop()\n",
    "            new_option_1 = \" \".join(split_1)\n",
    "            new_option_2 = \" \".join(split_2)\n",
    "            #return basic_probability(new_option_1,new_option_2,model)\n",
    "            return backoff_probability(new_option_1,new_option_2,model)\n",
    "            #return add_k_probability(new_option_1,new_option_2,model,.1,56951334,18881974)\n",
    "            \n",
    "    elif count_1 == 0:\n",
    "        count_1 = .1\n",
    "    elif count_2 == 0:\n",
    "        count_2 = .1\n",
    "        \n",
    "    prob_1 = count_1/(count_1+count_2)\n",
    "    prob_2 = count_2/(count_1+count_2)\n",
    "    \n",
    "    return prob_1, prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_probability(option_1,option_2,model):\n",
    "    if option_1 in model:\n",
    "        count_1 = model[option_1]\n",
    "    else:\n",
    "        count_1 = 0\n",
    "        \n",
    "    if option_2 in model:\n",
    "        count_2 = model[option_2]\n",
    "    else:\n",
    "        count_2 = 0\n",
    "        \n",
    "    if count_1 == 0 and count_2 == 0:\n",
    "        count_1 = 1\n",
    "        count_2 = 1    \n",
    "    elif count_1 == 0:\n",
    "        count_1 = .1\n",
    "    elif count_2 == 0:\n",
    "        count_2 = .1\n",
    "        \n",
    "    prob_1 = count_1/(count_1+count_2)\n",
    "    prob_2 = count_2/(count_1+count_2)\n",
    "    \n",
    "    return prob_1, prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_probability(option_1,option_2,model,weight):\n",
    "    if option_1 in model:\n",
    "        count_1 = model[option_1]\n",
    "    else:\n",
    "        count_1 = 0\n",
    "        \n",
    "    if option_2 in model:\n",
    "        count_2 = model[option_2]\n",
    "    else:\n",
    "        count_2 = 0\n",
    "        \n",
    "    if count_1 == 0 and count_2 == 0:\n",
    "        count_1 = 1\n",
    "        count_2 = 1    \n",
    "    elif count_1 == 0:\n",
    "        count_1 = .1\n",
    "    elif count_2 == 0:\n",
    "        count_2 = .1\n",
    "        \n",
    "    prob_1 = count_1/(count_1+count_2) *weight\n",
    "    prob_2 = count_2/(count_1+count_2) *weight\n",
    "    \n",
    "    return prob_1, prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14747572 2366058 654353 305936 169488\n",
      "18881974\n",
      "56951334\n"
     ]
    }
   ],
   "source": [
    "# N1 = sum(1 for x in model.values() if x==1)\n",
    "# N2 = sum(1 for x in model.values() if x==2)\n",
    "# N3 = sum(1 for x in model.values() if x==3)\n",
    "# N4 = sum(1 for x in model.values() if x==4)\n",
    "# N5 = sum(1 for x in model.values() if x==5)\n",
    "# print(str(N1)+' '+str(N2)+' '+str(N3)+' '+str(N4)+' '+str(N5))\n",
    "# print(len(model))\n",
    "# N = sum(model.values())\n",
    "# print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3186817592079723e-08\n"
     ]
    }
   ],
   "source": [
    "#print((0+1)/(N+len(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_probability(option_1,option_2,model,weights):\n",
    "    prob_1_arr=[]\n",
    "    prob_2_arr=[]\n",
    "    n_option_1 = option_1\n",
    "    n_option_2 = option_2\n",
    "    \n",
    "    while True:\n",
    "        # get basic probabilty and add to overall\n",
    "        c_prob_1, c_prob_2 = backoff_probability(n_option_1,n_option_2,model)\n",
    "        #c_prob_1, c_prob_2 = basic_probability(n_option_1,n_option_2,model)\n",
    "        #c_prob_1, c_prob_2 = add_k_probability(n_option_1,n_option_2,model,.1,56951334,18881974)\n",
    "        prob_1_arr.append(c_prob_1)\n",
    "        prob_2_arr.append(c_prob_2)\n",
    "        \n",
    "        # split the options\n",
    "        split_1 = n_option_1.split()\n",
    "        split_2 = n_option_2.split()\n",
    "        \n",
    "        #get option lengths\n",
    "        len_1 = len(split_1)\n",
    "        len_2 = len(split_2)\n",
    "        \n",
    "        if len_1 <= 1 or len_2 <= 1:\n",
    "            break\n",
    "        \n",
    "        if len(split_1) % 2 ==0:\n",
    "            split_1.pop(0)\n",
    "            split_2.pop(0)\n",
    "        else:\n",
    "            split_1.pop()\n",
    "            split_2.pop()\n",
    "        n_option_1 = \" \".join(split_1)\n",
    "        n_option_2 = \" \".join(split_2)   \n",
    "    \n",
    "    #multiply probabilities by weights\n",
    "    prob_1 = np.dot(weights,prob_1_arr)\n",
    "    prob_2 = np.dot(weights,prob_2_arr)\n",
    "    \n",
    "    return prob_1, prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_k_probability(option_1,option_2,model,k,N,V):\n",
    "    n_option_1 = option_1\n",
    "    n_option_2 = option_2\n",
    "    \n",
    "    if option_1 in model:\n",
    "        count_1 = model[option_1]\n",
    "    else:\n",
    "        count_1 = 0\n",
    "        \n",
    "    if option_2 in model:\n",
    "        count_2 = model[option_2]\n",
    "    else:\n",
    "        count_2 = 0\n",
    "        \n",
    "    count_1 = (count_1+k)*N/(N+k*V)\n",
    "    count_2 = (count_2+k)*N/(N+k*V)\n",
    "        \n",
    "    prob_1 = count_1/(count_1+count_2)\n",
    "    prob_2 = count_2/(count_1+count_2)\n",
    "    \n",
    "    return prob_1, prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00047898292541503906 (0.0076335877862595426, 0.9923664122137406)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "prob = interpolate_probability(choices[4937][0],choices[4937][1],model,[.1,.9,0])\n",
    "end = time.time()\n",
    "print(end-start, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected_runtime = (end-start)*20000\n",
    "#expected_runtime/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-190-8f08a6c7b847>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-190-8f08a6c7b847>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    weights = 1/Z * weights * exp(-adaptive_param*)\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def ada_boost(train):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    \n",
    "    results_array = []\n",
    "    #initialize weights\n",
    "    weights = []\n",
    "    for x in range(0,len(train)):\n",
    "        weights.append(1/len(train))\n",
    "        \n",
    "    for trial in range(0,K):\n",
    "        #train unigram with weights\n",
    "        model = train_model(new_train,N)\n",
    "        results = evaluate_weighted_model(model,choices,weights)\n",
    "        results_array.append(results)\n",
    "        success = write_output(output_name,results)\n",
    "        score = evaluate_results(output_name,dev_answers)\n",
    "        adaptive_param = 0.5*log((1-score)/score)\n",
    "        weights = 1/Z * weights * exp(adaptive_param)\n",
    "        \n",
    "    \n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    model = train_model(new_train,N)\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    results = evaluate_interp_model(model,choices,weights)\n",
    "    success = write_output(output_name,results)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, choices):\n",
    "    results = [['Id','Expected']]\n",
    "    for index, choice in enumerate(choices):\n",
    "        c1,c2 = basic_probability(choice[0],choice[1],model)\n",
    "        results.append([index+1,c1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_interp_model(model, choices, weights):\n",
    "    results = [['Id','Expected']]\n",
    "    for index, choice in enumerate(choices):\n",
    "        c1,c2 = interpolate_probability(choice[0],choice[1],model, weights)\n",
    "        results.append([index+1,c1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaulate_weighted_model(model, choices, weights):\n",
    "    results = [['Id','Expected']]\n",
    "    for index, choice in enumerate(choices):\n",
    "        c1,c2 = weighted_probability(choice[0],choice[1],model, weights[index])\n",
    "        results.append([index+1,c1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = evaluate_weighted_model(model,choices,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(filename,results):\n",
    "    out_file = open(filename,'w')\n",
    "    count =0\n",
    "    for line in results:\n",
    "        output = str(line[0]) + \",\" + str(line[1]) + \"\\n\"\n",
    "        out_file.write(output)\n",
    "    out_file.close()\n",
    "    return 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(prediction_file,actual_file):\n",
    "    with open(prediction_file) as file:\n",
    "        reader = csv.reader(file)\n",
    "        predictions = list(reader)\n",
    "    \n",
    "    with open(actual_file) as file:\n",
    "        reader = csv.reader(file)\n",
    "        actual = list(reader)\n",
    "    \n",
    "    if len(actual) != len(predictions):\n",
    "        print(\"Error: Files not the same length\")\n",
    "        return\n",
    "    \n",
    "    actual = np.array(actual)\n",
    "    actual = actual[1:,1].astype(np.float64)\n",
    "    predictions = np.array(predictions)\n",
    "    predictions = predictions[1:,1].astype(np.float64)\n",
    "    \n",
    "    log_loss_score = log_loss(actual, predictions, eps=1e-15)\n",
    "        \n",
    "    return log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8597526024197777"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_results(\"First_Dev_Test.csv\",\"dev_answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(output_name,train,test,N):\n",
    "    train_data = prepare_data(train,N)\n",
    "    model = train_model(train_data,N)\n",
    "    choices = prepare_test_data(test,N)\n",
    "    results = evaluate_model(model,choices)\n",
    "    write_output(output_name,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_interp_pipeline(output_name,train,test,N,weights):\n",
    "    train_data = prepare_data(train,N)\n",
    "    model = train_model(train_data,N)\n",
    "    choices = prepare_test_data(test,N)\n",
    "    results = evaluate_interp_model(model,choices,weights)\n",
    "    write_output(output_name,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_pipeline(\"trigram_with_bold_reassignment.csv\",\"train.txt\",\"test.txt\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_interp_pipeline(\"optimized_weight_pentagram.csv\",\"train.txt\",\"test.txt\",5,[0.1, 0.1, 0.7, 0.1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_dev_pipeline(output_name,train,dev_test,dev_answers,N,percent_split,weights):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    model = train_model(new_train,N)\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    results = evaluate_interp_model(model,choices,weights)\n",
    "    success = write_output(output_name,results)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-69f9ecf65786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_dev_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First_Dev_Test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dev_test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dev_answers.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-200-e9b1d5041488>\u001b[0m in \u001b[0;36mfull_dev_pipeline\u001b[0;34m(output_name, train, dev_test, dev_answers, N, percent_split, weights)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnew_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dev_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mchoices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_interp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-179-7f7b2817bd58>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_data, N)\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mn_forward\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meach_N\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     \u001b[0mngram\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_forward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = full_dev_pipeline(\"First_Dev_Test.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",4,10,[0.2, 0.7, 0.1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 1.0] 0.38062955591667336\n",
      "[0.0, 0.1, 0.9] 0.34355854928712437\n",
      "[0.0, 0.2, 0.8] 0.3136351846652727\n",
      "[0.0, 0.30000000000000004, 0.7] 0.28957332646596795\n",
      "[0.0, 0.4, 0.6] 0.269573376526344\n",
      "[0.0, 0.5, 0.5] 0.25193587771123865\n",
      "[0.0, 0.6000000000000001, 0.3999999999999999] 0.23895886886199058\n",
      "[0.0, 0.7000000000000001, 0.29999999999999993] 0.22030778975511348\n",
      "[0.0, 0.8, 0.19999999999999996] 0.20806457540148218\n",
      "[0.0, 0.9, 0.09999999999999998] 0.20116295263874215\n",
      "[0.0, 1.0, 0.0] 0.2017953799245475\n",
      "[0.1, 0.0, 0.9] 0.3358309672764408\n",
      "[0.1, 0.1, 0.8] 0.30924147987125666\n",
      "[0.1, 0.2, 0.7000000000000001] 0.2851049845188644\n",
      "[0.1, 0.30000000000000004, 0.6] 0.26665941676423005\n",
      "[0.1, 0.4, 0.5] 0.24545792507676092\n",
      "[0.1, 0.5, 0.4] 0.22822594324829476\n",
      "[0.1, 0.6000000000000001, 0.29999999999999993] 0.22085445652429167\n",
      "[0.1, 0.7000000000000001, 0.19999999999999993] 0.20644956598170813\n",
      "[0.1, 0.8, 0.09999999999999995] 0.19299391606001973\n",
      "[0.1, 0.9, -2.7755575615628914e-17] 0.18891790102385275\n",
      "[0.2, 0.0, 0.8] 0.30487593385422984\n",
      "[0.2, 0.1, 0.7] 0.28050113479518773\n",
      "[0.2, 0.2, 0.6000000000000001] 0.26100125985268036\n",
      "[0.2, 0.30000000000000004, 0.49999999999999994] 0.2423587667890579\n",
      "[0.2, 0.4, 0.39999999999999997] 0.22620532497889498\n",
      "[0.2, 0.5, 0.3] 0.2125711385430255\n",
      "[0.2, 0.6000000000000001, 0.1999999999999999] 0.19963336618182634\n",
      "[0.2, 0.7000000000000001, 0.09999999999999992] 0.1885674641350047\n",
      "[0.2, 0.8, -5.551115123125783e-17] 0.18838419503042042\n",
      "[0.30000000000000004, 0.0, 0.7] 0.27994094161389926\n",
      "[0.30000000000000004, 0.1, 0.6] 0.25762734131244325\n",
      "[0.30000000000000004, 0.2, 0.5] 0.24362824282496578\n",
      "[0.30000000000000004, 0.30000000000000004, 0.3999999999999999] 0.2242863250527342\n",
      "[0.30000000000000004, 0.4, 0.29999999999999993] 0.20774652244358163\n",
      "[0.30000000000000004, 0.5, 0.19999999999999996] 0.200951769507262\n",
      "[0.30000000000000004, 0.6000000000000001, 0.09999999999999987] 0.18794991582111256\n",
      "[0.30000000000000004, 0.7000000000000001, -1.1102230246251565e-16] 0.1821884858615676\n",
      "[0.4, 0.0, 0.6] 0.26019106440987033\n",
      "[0.4, 0.1, 0.5] 0.24024260151050014\n",
      "[0.4, 0.2, 0.4] 0.22498226658036263\n",
      "[0.4, 0.30000000000000004, 0.29999999999999993] 0.20896585413568589\n",
      "[0.4, 0.4, 0.19999999999999996] 0.19275299514868313\n",
      "[0.4, 0.5, 0.09999999999999998] 0.1847833661791746\n",
      "[0.4, 0.6000000000000001, -1.1102230246251565e-16] 0.17713046770133806\n",
      "[0.5, 0.0, 0.5] 0.2415329536132787\n",
      "[0.5, 0.1, 0.4] 0.22491180587659362\n",
      "[0.5, 0.2, 0.30000000000000004] 0.20931159037749564\n",
      "[0.5, 0.30000000000000004, 0.19999999999999996] 0.1942248317167347\n",
      "[0.5, 0.4, 0.09999999999999998] 0.18636263138246836\n",
      "[0.5, 0.5, 0.0] 0.18140483260792264\n",
      "[0.6000000000000001, 0.0, 0.3999999999999999] 0.22033986573669975\n",
      "[0.6000000000000001, 0.1, 0.29999999999999993] 0.20796339492146215\n",
      "[0.6000000000000001, 0.2, 0.19999999999999996] 0.19659365048024335\n",
      "[0.6000000000000001, 0.30000000000000004, 0.09999999999999987] 0.18634317118710353\n",
      "[0.6000000000000001, 0.4, -1.1102230246251565e-16] 0.18175304640619758\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-354-1de6c36210f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_dev_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dev_test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dev_answers.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-223-e9b1d5041488>\u001b[0m in \u001b[0;36mfull_dev_pipeline\u001b[0;34m(output_name, train, dev_test, dev_answers, N, percent_split, weights)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfull_dev_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_answers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpercent_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnew_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dev_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-345-3f929c615a6e>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(filename, N)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NFC\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[,.?\"“”]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msplit_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for x in np.arange(0,1.1,0.1):\n",
    "    if x == 1:\n",
    "        weights = [x,0,0]\n",
    "        print(weights,full_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",3,10,weights))\n",
    "    for y in np.arange (0,1.05-x,0.1):\n",
    "        z = 1-y-x\n",
    "        weights = [x,y,z]\n",
    "        print(weights,full_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",3,10,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.0, 0.0, 0.0, 0.9] 0.3592849652183154\n",
      "[0.1, 0.0, 0.0, 0.1, 0.8] 0.3311490991789249\n",
      "[0.1, 0.0, 0.0, 0.2, 0.7] 0.30760038048317145\n",
      "[0.1, 0.0, 0.0, 0.30000000000000004, 0.6] 0.2869986481387449\n",
      "[0.1, 0.0, 0.0, 0.4, 0.5] 0.26861367988811213\n",
      "[0.1, 0.0, 0.0, 0.5, 0.4] 0.25205284103686126\n",
      "[0.1, 0.0, 0.0, 0.6000000000000001, 0.29999999999999993] 0.23710540323869186\n",
      "[0.1, 0.0, 0.0, 0.7000000000000001, 0.19999999999999996] 0.2237025565816232\n",
      "[0.1, 0.0, 0.0, 0.8, 0.09999999999999998] 0.21196771460937552\n",
      "[0.1, 0.0, 0.0, 0.9, 0.0] 0.20269885529067716\n",
      "[0.1, 0.0, 0.1, 0.0, 0.8] 0.32671077433535384\n",
      "[0.1, 0.0, 0.1, 0.1, 0.7000000000000001] 0.30329969582707855\n",
      "[0.1, 0.0, 0.1, 0.2, 0.6000000000000001] 0.28278767939907595\n",
      "[0.1, 0.0, 0.1, 0.30000000000000004, 0.5] 0.2644590076198142\n",
      "[0.1, 0.0, 0.1, 0.4, 0.4] 0.24792750612404726\n",
      "[0.1, 0.0, 0.1, 0.5, 0.30000000000000004] 0.2329846290390802\n",
      "[0.1, 0.0, 0.1, 0.6000000000000001, 0.19999999999999996] 0.2195603756291684\n",
      "[0.1, 0.0, 0.1, 0.7000000000000001, 0.09999999999999998] 0.2077725244213236\n",
      "[0.1, 0.0, 0.1, 0.8, 0.0] 0.1983969045766627\n",
      "[0.1, 0.0, 0.2, 0.0, 0.7] 0.30051333026726557\n",
      "[0.1, 0.0, 0.2, 0.1, 0.6] 0.2800609765032065\n",
      "[0.1, 0.0, 0.2, 0.2, 0.49999999999999994] 0.2617726314295449\n",
      "[0.1, 0.0, 0.2, 0.30000000000000004, 0.3999999999999999] 0.2452646807254787\n",
      "[0.1, 0.0, 0.2, 0.4, 0.29999999999999993] 0.2303298154095313\n",
      "[0.1, 0.0, 0.2, 0.5, 0.19999999999999996] 0.21689786995589022\n",
      "[0.1, 0.0, 0.2, 0.6000000000000001, 0.09999999999999987] 0.20508467639731853\n",
      "[0.1, 0.0, 0.2, 0.7000000000000001, -1.1102230246251565e-16] 0.19565846005773804\n",
      "[0.1, 0.0, 0.30000000000000004, 0.0, 0.6] 0.27842515107777127\n",
      "[0.1, 0.0, 0.30000000000000004, 0.1, 0.5] 0.26016130732459564\n",
      "[0.1, 0.0, 0.30000000000000004, 0.2, 0.39999999999999997] 0.24366977981175753\n",
      "[0.1, 0.0, 0.30000000000000004, 0.30000000000000004, 0.29999999999999993] 0.2287421617463683\n",
      "[0.1, 0.0, 0.30000000000000004, 0.4, 0.19999999999999996] 0.21530778510961865\n",
      "[0.1, 0.0, 0.30000000000000004, 0.5, 0.09999999999999998] 0.20348168850028708\n",
      "[0.1, 0.0, 0.30000000000000004, 0.6000000000000001, -1.1102230246251565e-16] 0.1940319433778779\n",
      "[0.1, 0.0, 0.4, 0.0, 0.5] 0.25945382845098525\n",
      "[0.1, 0.0, 0.4, 0.1, 0.4] 0.24296736277904538\n",
      "[0.1, 0.0, 0.4, 0.2, 0.3] 0.22804290601790994\n",
      "[0.1, 0.0, 0.4, 0.30000000000000004, 0.19999999999999996] 0.21460723362480133\n",
      "[0.1, 0.0, 0.4, 0.4, 0.09999999999999998] 0.20277462192701848\n",
      "[0.1, 0.0, 0.4, 0.5, 0.0] 0.19331851178177284\n",
      "[0.1, 0.0, 0.5, 0.0, 0.4] 0.243083650255014\n",
      "[0.1, 0.0, 0.5, 0.1, 0.30000000000000004] 0.22815225188716703\n",
      "[0.1, 0.0, 0.5, 0.2, 0.2] 0.2147125055458078\n",
      "[0.1, 0.0, 0.5, 0.30000000000000004, 0.09999999999999998] 0.2028760270993381\n",
      "[0.1, 0.0, 0.5, 0.4, 0.0] 0.1934264511806089\n",
      "[0.1, 0.0, 0.6000000000000001, 0.0, 0.29999999999999993] 0.22905755364501834\n",
      "[0.1, 0.0, 0.6000000000000001, 0.1, 0.19999999999999993] 0.2156035400849962\n",
      "[0.1, 0.0, 0.6000000000000001, 0.2, 0.09999999999999992] 0.20376182581175636\n",
      "[0.1, 0.0, 0.6000000000000001, 0.30000000000000004, -1.1102230246251565e-16] 0.19432992520703388\n",
      "[0.1, 0.0, 0.7000000000000001, 0.0, 0.19999999999999996] 0.2173229153217166\n",
      "[0.1, 0.0, 0.7000000000000001, 0.1, 0.09999999999999995] 0.2054657789947519\n",
      "[0.1, 0.0, 0.7000000000000001, 0.2, -5.551115123125783e-17] 0.19606232390450767\n",
      "[0.1, 0.0, 0.8, 0.0, 0.09999999999999998] 0.20810795605317434\n",
      "[0.1, 0.0, 0.8, 0.1, -2.7755575615628914e-17] 0.19874301146575446\n",
      "[0.1, 0.0, 0.9, 0.0, 0.0] 0.20275743454416525\n",
      "[0.1, 0.1, 0.0, 0.0, 0.8] 0.3375060710521939\n",
      "[0.1, 0.1, 0.0, 0.1, 0.7000000000000001] 0.3132110660053589\n",
      "[0.1, 0.1, 0.0, 0.2, 0.6000000000000001] 0.2920472497629416\n",
      "[0.1, 0.1, 0.0, 0.30000000000000004, 0.5] 0.2731652341648446\n",
      "[0.1, 0.1, 0.0, 0.4, 0.4] 0.25612038083992217\n",
      "[0.1, 0.1, 0.0, 0.5, 0.30000000000000004] 0.240663966709091\n",
      "[0.1, 0.1, 0.0, 0.6000000000000001, 0.19999999999999996] 0.22668228497431003\n",
      "[0.1, 0.1, 0.0, 0.7000000000000001, 0.09999999999999998] 0.21421744915926533\n",
      "[0.1, 0.1, 0.0, 0.8, 0.0] 0.2038115271395801\n",
      "[0.1, 0.1, 0.1, 0.0, 0.7000000000000001] 0.3103352058975433\n",
      "[0.1, 0.1, 0.1, 0.1, 0.6000000000000001] 0.2892319685984819\n",
      "[0.1, 0.1, 0.1, 0.2, 0.5] 0.2703909983583419\n",
      "[0.1, 0.1, 0.1, 0.30000000000000004, 0.4] 0.25337029488311213\n",
      "[0.1, 0.1, 0.1, 0.4, 0.30000000000000004] 0.2379224265763172\n",
      "[0.1, 0.1, 0.1, 0.5, 0.20000000000000007] 0.2239335764291709\n",
      "[0.1, 0.1, 0.1, 0.6000000000000001, 0.09999999999999998] 0.21144401578275313\n",
      "[0.1, 0.1, 0.1, 0.7000000000000001, 0.0] 0.20098907022575702\n",
      "[0.1, 0.1, 0.2, 0.0, 0.6000000000000001] 0.2875239322497597\n",
      "[0.1, 0.1, 0.2, 0.1, 0.5000000000000001] 0.26870798100227733\n",
      "[0.1, 0.1, 0.2, 0.2, 0.4000000000000001] 0.2517041423385727\n",
      "[0.1, 0.1, 0.2, 0.30000000000000004, 0.30000000000000004] 0.23626391982262804\n",
      "[0.1, 0.1, 0.2, 0.4, 0.20000000000000007] 0.22227302800239523\n",
      "[0.1, 0.1, 0.2, 0.5, 0.10000000000000009] 0.20977100944253696\n",
      "[0.1, 0.1, 0.2, 0.6000000000000001, 0.0] 0.19929353408690634\n",
      "[0.1, 0.1, 0.30000000000000004, 0.0, 0.5] 0.2679323202721073\n",
      "[0.1, 0.1, 0.30000000000000004, 0.1, 0.4] 0.2509339635026288\n",
      "[0.1, 0.1, 0.30000000000000004, 0.2, 0.3] 0.23549726611298777\n",
      "[0.1, 0.1, 0.30000000000000004, 0.30000000000000004, 0.19999999999999996] 0.22150541401010906\n",
      "[0.1, 0.1, 0.30000000000000004, 0.4, 0.09999999999999998] 0.20899722575484814\n",
      "[0.1, 0.1, 0.30000000000000004, 0.5, 0.0] 0.19851397083765018\n",
      "[0.1, 0.1, 0.4, 0.0, 0.4] 0.25097881071035216\n",
      "[0.1, 0.1, 0.4, 0.1, 0.30000000000000004] 0.23553557819805018\n",
      "[0.1, 0.1, 0.4, 0.2, 0.2] 0.22153999202644908\n",
      "[0.1, 0.1, 0.4, 0.30000000000000004, 0.09999999999999998] 0.2090282316053003\n",
      "[0.1, 0.1, 0.4, 0.4, 0.0] 0.19855175967487063\n",
      "[0.1, 0.1, 0.5, 0.0, 0.30000000000000004] 0.23635915988851547\n",
      "[0.1, 0.1, 0.5, 0.1, 0.20000000000000004] 0.22234973713110184\n",
      "[0.1, 0.1, 0.5, 0.2, 0.10000000000000003] 0.20983304127480554\n",
      "[0.1, 0.1, 0.5, 0.30000000000000004, 0.0] 0.1993741782940996\n",
      "[0.1, 0.1, 0.6000000000000001, 0.0, 0.19999999999999996] 0.2239668445629868\n",
      "[0.1, 0.1, 0.6000000000000001, 0.1, 0.09999999999999995] 0.21143516518956754\n",
      "[0.1, 0.1, 0.6000000000000001, 0.2, -5.551115123125783e-17] 0.20100433152745018\n",
      "[0.1, 0.1, 0.7000000000000001, 0.0, 0.09999999999999998] 0.21393426823872494\n",
      "[0.1, 0.1, 0.7000000000000001, 0.1, -2.7755575615628914e-17] 0.2035410751985618\n",
      "[0.1, 0.1, 0.8, 0.0, 0.0] 0.2073136324084928\n",
      "[0.1, 0.2, 0.0, 0.0, 0.7] 0.3219914928018734\n",
      "[0.1, 0.2, 0.0, 0.1, 0.6] 0.3001172810047328\n",
      "[0.1, 0.2, 0.0, 0.2, 0.49999999999999994] 0.2806741110320042\n",
      "[0.1, 0.2, 0.0, 0.30000000000000004, 0.3999999999999999] 0.2631322635643814\n",
      "[0.1, 0.2, 0.0, 0.4, 0.29999999999999993] 0.2471989095314936\n",
      "[0.1, 0.2, 0.0, 0.5, 0.19999999999999996] 0.2327248940257781\n",
      "[0.1, 0.2, 0.0, 0.6000000000000001, 0.09999999999999987] 0.21970667494687712\n",
      "[0.1, 0.2, 0.0, 0.7000000000000001, -1.1102230246251565e-16] 0.20857766347575313\n",
      "[0.1, 0.2, 0.1, 0.0, 0.6] 0.2983246134369592\n",
      "[0.1, 0.2, 0.1, 0.1, 0.5] 0.2789074011813576\n",
      "[0.1, 0.2, 0.1, 0.2, 0.39999999999999997] 0.26138312365915656\n",
      "[0.1, 0.2, 0.1, 0.30000000000000004, 0.29999999999999993] 0.24545796736070052\n",
      "[0.1, 0.2, 0.1, 0.4, 0.19999999999999996] 0.2309823575457899\n",
      "[0.1, 0.2, 0.1, 0.5, 0.09999999999999998] 0.21795205960724484\n",
      "[0.1, 0.2, 0.1, 0.6000000000000001, -1.1102230246251565e-16] 0.20680109616697354\n",
      "[0.1, 0.2, 0.2, 0.0, 0.49999999999999994] 0.2780596639030396\n",
      "[0.1, 0.2, 0.2, 0.1, 0.3999999999999999] 0.26054135266186235\n",
      "[0.1, 0.2, 0.2, 0.2, 0.29999999999999993] 0.2446201132628953\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-85b4068a9ce0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrest_of_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_answers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-203-8c442012734d>\u001b[0m in \u001b[0;36mrest_of_dev\u001b[0;34m(model, choices, output_name, dev_answers, weights)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_interp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-195-bed772f7a17d>\u001b[0m in \u001b[0;36mevaluate_results\u001b[0;34m(prediction_file, actual_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model,choices,output_name,dev_answers = half_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",5,10)\n",
    "for x in np.arange(0.1,1.1,0.1):\n",
    "    if x == 1:\n",
    "        weights = [x,0,0,0,0]\n",
    "        print(weights, rest_of_dev(model,choices,output_name,dev_answers,weights))\n",
    "    for y in np.arange (0,1.05-x,0.1):\n",
    "        if y ==1:\n",
    "            weights = [0,y,0,0,0]\n",
    "            print(weights,rest_of_dev(model,choices,output_name,dev_answers,weights))\n",
    "        for z in np.arange(0,1.05-x-y,0.1):\n",
    "            if z ==1:\n",
    "                weights = [0,0,z,0,0]\n",
    "                print(weights,rest_of_dev(model,choices,output_name,dev_answers,weights))\n",
    "            for a in np.arange(0,1.05-x-y-z,0.1):\n",
    "                b = 1-x-y-z-a\n",
    "                weights = [x,y,z,a,b]\n",
    "                print(weights,rest_of_dev(model,choices,output_name,dev_answers,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33740994750617076"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",4,10,[0.2,0.7,0.1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_dev_pipeline(output_name,train,dev_test,dev_answers,N,percent_split):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    model = train_model(new_train,N)\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    return model,choices,output_name,dev_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_of_dev(model,choices,output_name,dev_answers,weights):\n",
    "    results = evaluate_interp_model(model,choices,weights)\n",
    "    success = write_output(output_name,results)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,choices,output_name,dev_answers = half_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",6,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0,0.0,.2,.3,.5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18820252692236433"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_of_dev(model,choices,output_name,dev_answers,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_resample(train_data):\n",
    "    train_size = len(train_data)\n",
    "    new_train = []\n",
    "    for x in range(0,len(train_data)):\n",
    "        new_train.append(train_data[math.floor(random.random()*train_size)])\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_test(output_name,train,dev_test,dev_answers,N,percent_split,weights,bags):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    overall_results_array = []\n",
    "    mean_array = [['ID','Expected']]\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    for bag in range(0,bags):\n",
    "        bootstrapped_train = bootstrap_resample(new_train)\n",
    "        model = train_model(bootstrapped_train,N)\n",
    "        results = evaluate_interp_model(model,choices,weights)\n",
    "        overall_results_array.append(results)\n",
    "    for x in range(1,len(results)):\n",
    "        mean = 0\n",
    "        for result_array in overall_results_array:\n",
    "            mean += result_array[x][1]\n",
    "        mean = mean/len(overall_results_array)\n",
    "        mean_array.append([x,mean])\n",
    "    success = write_output(output_name,mean_array)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = bagging_test(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",4,10,[0.1,0.1,0.7,0.1,0],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2821542034186898"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_real(output_name,train,test,N,weights,bags):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    overall_results_array = []\n",
    "    mean_array = [['ID','Expected']]\n",
    "    choices = prepare_test_data(test,N)\n",
    "    for bag in range(0,bags):\n",
    "        print(bag)\n",
    "        bootstrapped_train = bootstrap_resample(train_data)\n",
    "        model = train_model(bootstrapped_train,N)\n",
    "        results = evaluate_interp_model(model,choices,weights)\n",
    "        overall_results_array.append(results)\n",
    "    for x in range(1,len(results)):\n",
    "        mean = 0\n",
    "        for result_array in overall_results_array:\n",
    "            mean += result_array[x][1]\n",
    "        mean = mean/len(overall_results_array)\n",
    "        mean_array.append([x,mean])\n",
    "    success = write_output(output_name,mean_array)\n",
    "    return output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-79a7d0fef954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbagging_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bagging_quad.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-230-37f59f566c74>\u001b[0m in \u001b[0;36mbagging_real\u001b[0;34m(output_name, train, test, N, weights, bags)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mbootstrapped_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrapped_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_interp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moverall_results_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-179-7f7b2817bd58>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_data, N)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0meach_N\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mn_forward\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meach_N\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                     \u001b[0mngram\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_forward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bagging_real(\"bagging_quad.csv\",\"train.txt\",\"test.txt\",4,[0.2,0.7,0.1,0],100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_best_solutions(names):\n",
    "    all_predictions = []\n",
    "    mean_array = [['ID','Expected']]\n",
    "    pred_len = 0\n",
    "    for name in names:\n",
    "        with open(name) as file:\n",
    "            reader = csv.reader(file)\n",
    "            predictions = list(reader)\n",
    "#         predictions = np.array(predictions)\n",
    "#         predictions = predictions[1:,1].astype(np.float64)\n",
    "            all_predictions.append(predictions)\n",
    "            pred_len = len(predictions)\n",
    "    for x in range(1,pred_len):\n",
    "        mean = 0\n",
    "        for ind,pred_list in enumerate(all_predictions):\n",
    "            mean += float(pred_list[x][1])\n",
    "        mean = mean/len(all_predictions)\n",
    "        mean_array.append([x,mean])\n",
    "    \n",
    "    return mean_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['optimized_weight_pentagram.csv','optimized_weight_quadgram.csv','combined_best_tries.csv','a_very_bold_trigram.csv','optimized_weight_trigram.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compile_best_solutions(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ID', 'Expected'],\n",
       " [1, 0.9856907036585907],\n",
       " [2, 0.9255309037074027],\n",
       " [3, 0.9486942831189358],\n",
       " [4, 0.9423442487264475],\n",
       " [5, 0.9551780992875495],\n",
       " [6, 0.9995605248642334],\n",
       " [7, 0.9420145810372812],\n",
       " [8, 0.9858172528653165],\n",
       " [9, 0.981202333203405],\n",
       " [10, 0.9403607662719293],\n",
       " [11, 0.9838988638171461],\n",
       " [12, 0.9200377409624592],\n",
       " [13, 0.943513327239148],\n",
       " [14, 0.9200377409624592],\n",
       " [15, 0.9890406849571379],\n",
       " [16, 0.9903641428012957],\n",
       " [17, 0.9759193572212551],\n",
       " [18, 0.06812538536833639],\n",
       " [19, 0.9200377409624592],\n",
       " [20, 0.9918216872016232],\n",
       " [21, 0.9814221444825801],\n",
       " [22, 0.9806368642719546],\n",
       " [23, 0.9682182883253733],\n",
       " [24, 0.9964997376749836],\n",
       " [25, 0.9935656578753773],\n",
       " [26, 0.5556659158923358],\n",
       " [27, 0.9768688187152149],\n",
       " [28, 0.9725596173133069],\n",
       " [29, 0.924915656241529],\n",
       " [30, 0.9906986234614548],\n",
       " [31, 0.9898722200990934],\n",
       " [32, 0.914658229795603],\n",
       " [33, 0.9617844560759921],\n",
       " [34, 0.9974307335974298],\n",
       " [35, 0.9925418678431808],\n",
       " [36, 0.9744834110926149],\n",
       " [37, 0.9961301694892768],\n",
       " [38, 0.9991050388806999],\n",
       " [39, 0.7266155822387724],\n",
       " [40, 0.9924297652093605],\n",
       " [41, 0.9987867951452047],\n",
       " [42, 0.9972107963754038],\n",
       " [43, 0.9816058269647339],\n",
       " [44, 0.9681625257715991],\n",
       " [45, 0.9862285280341846],\n",
       " [46, 0.9995357087831632],\n",
       " [47, 0.9802914727659233],\n",
       " [48, 0.9997008197228983],\n",
       " [49, 0.9466536682084861],\n",
       " [50, 0.9959412543180071],\n",
       " [51, 0.8656504944251655],\n",
       " [52, 0.9778464147565217],\n",
       " [53, 0.7564650961925504],\n",
       " [54, 0.9517253761423227],\n",
       " [55, 0.9900465910050279],\n",
       " [56, 0.9902243924024219],\n",
       " [57, 0.9602590971221708],\n",
       " [58, 0.9995496339497679],\n",
       " [59, 0.9796057612177208],\n",
       " [60, 0.9815751121331553],\n",
       " [61, 0.9352638045458408],\n",
       " [62, 0.9311709540843018],\n",
       " [63, 0.987902491550631],\n",
       " [64, 0.9436252641097627],\n",
       " [65, 0.32490599261260905],\n",
       " [66, 0.9965032471861827],\n",
       " [67, 0.9517348594534057],\n",
       " [68, 0.9632655499151053],\n",
       " [69, 0.7591132695814637],\n",
       " [70, 0.9969515922860641],\n",
       " [71, 0.9847610409769899],\n",
       " [72, 0.9744116346941121],\n",
       " [73, 0.9623356236142502],\n",
       " [74, 0.9623716885347393],\n",
       " [75, 0.9200377409624592],\n",
       " [76, 0.9815329885880246],\n",
       " [77, 0.9645003893038646],\n",
       " [78, 0.9615253217354092],\n",
       " [79, 0.9294667085269875],\n",
       " [80, 0.9969822163950207],\n",
       " [81, 0.9500988955925024],\n",
       " [82, 0.9696453687690239],\n",
       " [83, 0.941006435205099],\n",
       " [84, 0.9911286408689562],\n",
       " [85, 0.9705434430035934],\n",
       " [86, 0.9897721209458844],\n",
       " [87, 0.9167911805247411],\n",
       " [88, 0.9947348030678649],\n",
       " [89, 0.9975803530417376],\n",
       " [90, 0.9450506823036333],\n",
       " [91, 0.9978381230048952],\n",
       " [92, 0.9578387786300221],\n",
       " [93, 0.9987622861152661],\n",
       " [94, 0.9948682329493522],\n",
       " [95, 0.9123229597306924],\n",
       " [96, 0.9983786959636671],\n",
       " [97, 0.9200377409624592],\n",
       " [98, 0.9999801293960914],\n",
       " [99, 0.9200377409624592],\n",
       " [100, 0.963684462221913],\n",
       " [101, 0.9995202159394287],\n",
       " [102, 0.9967528446217422],\n",
       " [103, 0.9200377409624592],\n",
       " [104, 0.9965342343393153],\n",
       " [105, 0.9839077272700344],\n",
       " [106, 0.94024667195666],\n",
       " [107, 0.9934350812480618],\n",
       " [108, 0.9774401559413031],\n",
       " [109, 0.9941201850830025],\n",
       " [110, 0.9981158159572983],\n",
       " [111, 0.9992094268650312],\n",
       " [112, 0.9377978947381506],\n",
       " [113, 0.9465354969773954],\n",
       " [114, 0.9414220477504667],\n",
       " [115, 0.9941623778057599],\n",
       " [116, 0.981510553824285],\n",
       " [117, 0.9573112625616254],\n",
       " [118, 0.9892862329818121],\n",
       " [119, 0.9200377409624592],\n",
       " [120, 0.9658892519977424],\n",
       " [121, 0.9200377409624592],\n",
       " [122, 0.978526146412243],\n",
       " [123, 0.7982083333333334],\n",
       " [124, 0.8566195037460467],\n",
       " [125, 0.9999904925615926],\n",
       " [126, 0.9912119579550633],\n",
       " [127, 0.9694368938677442],\n",
       " [128, 0.9839779264187257],\n",
       " [129, 0.8306526433955478],\n",
       " [130, 0.9758869496640556],\n",
       " [131, 0.9618803740212833],\n",
       " [132, 0.030534859829074022],\n",
       " [133, 0.9220707874990834],\n",
       " [134, 0.993631468870068],\n",
       " [135, 0.9563581482047289],\n",
       " [136, 0.9734362814741655],\n",
       " [137, 0.941161920530235],\n",
       " [138, 0.9995706342186835],\n",
       " [139, 0.9876864343814289],\n",
       " [140, 0.9901499287965863],\n",
       " [141, 0.9814583842112157],\n",
       " [142, 0.9911548156167506],\n",
       " [143, 0.9877247653969933],\n",
       " [144, 0.9200377409624592],\n",
       " [145, 0.9623365488096969],\n",
       " [146, 0.9935882596767491],\n",
       " [147, 0.9991744035932282],\n",
       " [148, 0.9552210090354951],\n",
       " [149, 0.9200377409624592],\n",
       " [150, 0.9952165681741778],\n",
       " [151, 0.9957751422282095],\n",
       " [152, 0.9920097431201975],\n",
       " [153, 0.947281978903183],\n",
       " [154, 0.974771930005678],\n",
       " [155, 0.9903114324441269],\n",
       " [156, 0.9849634421948534],\n",
       " [157, 0.9955552503365676],\n",
       " [158, 0.9660107707897307],\n",
       " [159, 0.9379869068597056],\n",
       " [160, 0.9474407247924443],\n",
       " [161, 0.9252437476419797],\n",
       " [162, 0.9200377409624592],\n",
       " [163, 0.8785226266142694],\n",
       " [164, 0.9930961218320492],\n",
       " [165, 0.9987346450959865],\n",
       " [166, 0.9902034208624529],\n",
       " [167, 0.999542184160671],\n",
       " [168, 0.9718938917737953],\n",
       " [169, 0.9935076130252346],\n",
       " [170, 0.990810123809905],\n",
       " [171, 0.9886615617469742],\n",
       " [172, 0.9200377409624592],\n",
       " [173, 0.9888224620595369],\n",
       " [174, 0.9710317434910578],\n",
       " [175, 0.9941293197400585],\n",
       " [176, 0.9745981101591866],\n",
       " [177, 0.9537326249223419],\n",
       " [178, 0.9251352660436314],\n",
       " [179, 0.9830320433688339],\n",
       " [180, 0.9911775362796827],\n",
       " [181, 0.9942116216031096],\n",
       " [182, 0.9426960377403807],\n",
       " [183, 0.99023724798077],\n",
       " [184, 0.9573943747941748],\n",
       " [185, 0.9299241738934892],\n",
       " [186, 0.9760762292818613],\n",
       " [187, 0.9928757133282812],\n",
       " [188, 0.9482689874491024],\n",
       " [189, 0.9477328098950506],\n",
       " [190, 0.9968533228788455],\n",
       " [191, 0.9793424084183275],\n",
       " [192, 0.9877896924141296],\n",
       " [193, 0.9486034799330302],\n",
       " [194, 0.974116274511046],\n",
       " [195, 0.9871766345932647],\n",
       " [196, 0.9196950962485332],\n",
       " [197, 0.9930715190395617],\n",
       " [198, 0.9200377409624592],\n",
       " [199, 0.9963208678831632],\n",
       " [200, 0.9903391895200683],\n",
       " [201, 0.9200377409624592],\n",
       " [202, 0.9588239817804067],\n",
       " [203, 0.980974086778174],\n",
       " [204, 0.9866871259138101],\n",
       " [205, 0.917061682476749],\n",
       " [206, 0.9885699556330156],\n",
       " [207, 0.9200377409624592],\n",
       " [208, 0.9719197477804083],\n",
       " [209, 0.9960191786562976],\n",
       " [210, 0.9879621757548062],\n",
       " [211, 0.9800173560913997],\n",
       " [212, 0.9886599985179731],\n",
       " [213, 0.9360690674667873],\n",
       " [214, 0.9064236841997874],\n",
       " [215, 0.9200377409624592],\n",
       " [216, 0.9959682631117263],\n",
       " [217, 0.9790442541901253],\n",
       " [218, 0.9075194866311376],\n",
       " [219, 0.995949877789298],\n",
       " [220, 0.9681632088814413],\n",
       " [221, 0.9904561906089612],\n",
       " [222, 0.941492063267431],\n",
       " [223, 0.9976833381029883],\n",
       " [224, 0.9490766218370718],\n",
       " [225, 0.9695192637882674],\n",
       " [226, 0.9993589641036614],\n",
       " [227, 0.9793442803045066],\n",
       " [228, 0.9539217839736157],\n",
       " [229, 0.9826078625013711],\n",
       " [230, 0.9913158647947821],\n",
       " [231, 0.9065834348099957],\n",
       " [232, 0.9200377409624592],\n",
       " [233, 0.9705989747294608],\n",
       " [234, 0.9536703104607588],\n",
       " [235, 0.9744116609045423],\n",
       " [236, 0.9989605134378985],\n",
       " [237, 0.9995062010735747],\n",
       " [238, 0.9200377409624592],\n",
       " [239, 0.9684392062719575],\n",
       " [240, 0.9929733919028509],\n",
       " [241, 0.9411172748434964],\n",
       " [242, 0.962314670209568],\n",
       " [243, 0.9830753518195398],\n",
       " [244, 0.9532989459163588],\n",
       " [245, 0.9301748629983366],\n",
       " [246, 0.9942620153163938],\n",
       " [247, 0.9700476579690189],\n",
       " [248, 0.9997813636283363],\n",
       " [249, 0.9918577032649477],\n",
       " [250, 0.9702139389953306],\n",
       " [251, 0.9429605544760538],\n",
       " [252, 0.9859929969143015],\n",
       " [253, 0.9879682952850006],\n",
       " [254, 0.9890333069197149],\n",
       " [255, 0.9480506501181443],\n",
       " [256, 0.9987317003490874],\n",
       " [257, 0.9753578136529557],\n",
       " [258, 0.9638737957974517],\n",
       " [259, 0.9168400391940089],\n",
       " [260, 0.9756929638919797],\n",
       " [261, 0.9986453758990725],\n",
       " [262, 0.9980818276911426],\n",
       " [263, 0.9708357157090101],\n",
       " [264, 0.9793424084183275],\n",
       " [265, 0.9800112590981822],\n",
       " [266, 0.9991965209346165],\n",
       " [267, 0.9963575309217724],\n",
       " [268, 0.9200377409624592],\n",
       " [269, 0.983772090315771],\n",
       " [270, 0.9945940309191851],\n",
       " [271, 0.9785519964624646],\n",
       " [272, 0.9532966826307204],\n",
       " [273, 0.9886335430344602],\n",
       " [274, 0.958425415842535],\n",
       " [275, 0.940769844889107],\n",
       " [276, 0.9645003893038646],\n",
       " [277, 0.9892736271192234],\n",
       " [278, 0.9598371975712332],\n",
       " [279, 0.9458419183253373],\n",
       " [280, 0.9949063405331948],\n",
       " [281, 0.9996749976783613],\n",
       " [282, 0.9566636370456811],\n",
       " [283, 0.986178066705965],\n",
       " [284, 0.9775676899223091],\n",
       " [285, 0.9944262183701369],\n",
       " [286, 0.9308714853214111],\n",
       " [287, 0.7912635548474031],\n",
       " [288, 0.9316317801823264],\n",
       " [289, 0.9684017039145034],\n",
       " [290, 0.9806364503882288],\n",
       " [291, 0.9200377409624592],\n",
       " [292, 0.9687456067832917],\n",
       " [293, 0.9517371416291036],\n",
       " [294, 0.9904646828622422],\n",
       " [295, 0.8155463677057047],\n",
       " [296, 0.9200377409624592],\n",
       " [297, 0.9385531710444635],\n",
       " [298, 0.9903643778646783],\n",
       " [299, 0.03685037556935802],\n",
       " [300, 0.9200377409624592],\n",
       " [301, 0.9961722084606901],\n",
       " [302, 0.9842905689266956],\n",
       " [303, 0.9681364301336879],\n",
       " [304, 0.9294220483415243],\n",
       " [305, 0.9925119861697235],\n",
       " [306, 0.24479214771336552],\n",
       " [307, 0.9625415315802364],\n",
       " [308, 0.9876387415952215],\n",
       " [309, 0.9899933954912795],\n",
       " [310, 0.9952257959579022],\n",
       " [311, 0.9885983655946704],\n",
       " [312, 0.9814558081193473],\n",
       " [313, 0.5666865184186568],\n",
       " [314, 0.9626500082305638],\n",
       " [315, 0.9935766654732895],\n",
       " [316, 0.9955464692529645],\n",
       " [317, 0.9410944279146891],\n",
       " [318, 0.949198033468312],\n",
       " [319, 0.9958493916720788],\n",
       " [320, 0.9982388355444389],\n",
       " [321, 0.9248058127702382],\n",
       " [322, 0.9179424174052768],\n",
       " [323, 0.9901526327514837],\n",
       " [324, 0.9968023436593283],\n",
       " [325, 0.7993889061207609],\n",
       " [326, 0.9438517546507704],\n",
       " [327, 0.9783345589029627],\n",
       " [328, 0.9696598522103324],\n",
       " [329, 0.9361725497437551],\n",
       " [330, 0.7044498520003402],\n",
       " [331, 0.9734413543376489],\n",
       " [332, 0.9950504126586452],\n",
       " [333, 0.9952806855550962],\n",
       " [334, 0.9751208925987213],\n",
       " [335, 0.9335025699954516],\n",
       " [336, 0.9845519642159534],\n",
       " [337, 0.9200377409624592],\n",
       " [338, 0.9755895781911661],\n",
       " [339, 0.9903066742708612],\n",
       " [340, 0.9805444900040354],\n",
       " [341, 0.9250840160155691],\n",
       " [342, 0.982041631667836],\n",
       " [343, 0.995380494364848],\n",
       " [344, 0.9200377409624592],\n",
       " [345, 0.9724994215190226],\n",
       " [346, 0.9683424093532441],\n",
       " [347, 0.49580007483709093],\n",
       " [348, 0.9335733985730144],\n",
       " [349, 0.9200377409624592],\n",
       " [350, 0.9360380978234056],\n",
       " [351, 0.7512638888888888],\n",
       " [352, 0.955281460582088],\n",
       " [353, 0.9950469033185154],\n",
       " [354, 0.9997127732189319],\n",
       " [355, 0.9807144736329562],\n",
       " [356, 0.9525731323587496],\n",
       " [357, 0.9402877244613341],\n",
       " [358, 0.9868535006721],\n",
       " [359, 0.9087548389386624],\n",
       " [360, 0.9775820790574462],\n",
       " [361, 0.980759907526641],\n",
       " [362, 0.95331232350612],\n",
       " [363, 0.9997350611985661],\n",
       " [364, 0.9176348030234367],\n",
       " [365, 0.9906506904946326],\n",
       " [366, 0.8094147740968088],\n",
       " [367, 0.995524297531252],\n",
       " [368, 0.97981341572621],\n",
       " [369, 0.9200377409624592],\n",
       " [370, 0.9806771494994138],\n",
       " [371, 0.9983551261305103],\n",
       " [372, 0.9683919436970083],\n",
       " [373, 0.9951404432506366],\n",
       " [374, 0.9648530872830683],\n",
       " [375, 0.9200377409624592],\n",
       " [376, 0.9991080388791268],\n",
       " [377, 0.9082642683056579],\n",
       " [378, 0.9719366364295612],\n",
       " [379, 0.9897615968665427],\n",
       " [380, 0.9809377662882387],\n",
       " [381, 0.9682184550998107],\n",
       " [382, 0.9975041991491509],\n",
       " [383, 0.99470029405838],\n",
       " [384, 0.99743826285045],\n",
       " [385, 0.9802739385536586],\n",
       " [386, 0.9488529897702266],\n",
       " [387, 0.9567170534902326],\n",
       " [388, 0.9800386607636897],\n",
       " [389, 0.9479220036576452],\n",
       " [390, 0.9739150499081397],\n",
       " [391, 0.9200377409624592],\n",
       " [392, 0.9883245411594173],\n",
       " [393, 0.9363052702304258],\n",
       " [394, 0.9620911051720867],\n",
       " [395, 0.9850803877625012],\n",
       " [396, 0.9621052077378719],\n",
       " [397, 0.9662708175279742],\n",
       " [398, 0.9967682014489888],\n",
       " [399, 0.9980491635183734],\n",
       " [400, 0.9998548825941175],\n",
       " [401, 0.995364299952119],\n",
       " [402, 0.9534215779886452],\n",
       " [403, 0.991613507816178],\n",
       " [404, 0.9898898501666421],\n",
       " [405, 0.9977878284499436],\n",
       " [406, 0.8934958252855368],\n",
       " [407, 0.9882887267557114],\n",
       " [408, 0.99461338067224],\n",
       " [409, 0.9886831972350455],\n",
       " [410, 0.9637343686001512],\n",
       " [411, 0.9840101470946975],\n",
       " [412, 0.9747294292200873],\n",
       " [413, 0.9250952919857527],\n",
       " [414, 0.9863520962781083],\n",
       " [415, 0.9752537849839122],\n",
       " [416, 0.978551666103237],\n",
       " [417, 0.9940869543051015],\n",
       " [418, 0.999896497426757],\n",
       " [419, 0.9361815066218423],\n",
       " [420, 0.9015876492186663],\n",
       " [421, 0.9929712127385819],\n",
       " [422, 0.9945415352688247],\n",
       " [423, 0.9934865819746493],\n",
       " [424, 0.9960130270692993],\n",
       " [425, 0.9553452941814811],\n",
       " [426, 0.9479065593667981],\n",
       " [427, 0.9886172574343537],\n",
       " [428, 0.9691655598024846],\n",
       " [429, 0.9805458410777668],\n",
       " [430, 0.9200377409624592],\n",
       " [431, 0.9200377409624592],\n",
       " [432, 0.9824573579840798],\n",
       " [433, 0.9898704808815755],\n",
       " [434, 0.9815967429589044],\n",
       " [435, 0.9899785808125671],\n",
       " [436, 0.9969442166255803],\n",
       " [437, 0.930747948123849],\n",
       " [438, 0.9970536244531267],\n",
       " [439, 0.9942922763269413],\n",
       " [440, 0.9767107614144969],\n",
       " [441, 0.9938907866907915],\n",
       " [442, 0.9793442803045066],\n",
       " [443, 0.9915576621508041],\n",
       " [444, 0.9955793386410031],\n",
       " [445, 0.9473595712956039],\n",
       " [446, 0.9095169641761747],\n",
       " [447, 0.8746361273649084],\n",
       " [448, 0.9986134258622773],\n",
       " [449, 0.9681514689473272],\n",
       " [450, 0.9992436382090577],\n",
       " [451, 0.963132996407215],\n",
       " [452, 0.9253844452817022],\n",
       " [453, 0.9553452941814811],\n",
       " [454, 0.9950660441544361],\n",
       " [455, 0.999896497426757],\n",
       " [456, 0.9253856684924784],\n",
       " [457, 0.9890049879603688],\n",
       " [458, 0.998975043611398],\n",
       " [459, 0.9250603776402915],\n",
       " [460, 0.9245551137970004],\n",
       " [461, 0.9747949306894645],\n",
       " [462, 0.9294232442546596],\n",
       " [463, 0.9990276217099165],\n",
       " [464, 0.9955337579975012],\n",
       " [465, 0.9200377409624592],\n",
       " [466, 0.9954006303241277],\n",
       " [467, 0.9999801293960914],\n",
       " [468, 0.9945726907861022],\n",
       " [469, 0.9800687239939417],\n",
       " [470, 0.9960324849297397],\n",
       " [471, 0.9806468757368254],\n",
       " [472, 0.9896034619711902],\n",
       " [473, 0.9638622922300897],\n",
       " [474, 0.8847321430332048],\n",
       " [475, 0.945919628156409],\n",
       " [476, 0.9532639233365028],\n",
       " [477, 0.886253742106148],\n",
       " [478, 0.9415707351663778],\n",
       " [479, 0.9814793587849904],\n",
       " [480, 0.9948705985342119],\n",
       " [481, 0.9985226321160049],\n",
       " [482, 0.9875625175584035],\n",
       " [483, 0.9438556645260758],\n",
       " [484, 0.999842087435907],\n",
       " [485, 0.9989287388148741],\n",
       " [486, 0.9533808870596122],\n",
       " [487, 0.953692064189968],\n",
       " [488, 0.9200377409624592],\n",
       " [489, 0.8004217508141467],\n",
       " [490, 0.9838575021893877],\n",
       " [491, 0.9919437162354713],\n",
       " [492, 0.9684021253643929],\n",
       " [493, 0.9616729873202013],\n",
       " [494, 0.9438328090469573],\n",
       " [495, 0.9468356569458075],\n",
       " [496, 0.9987670664869684],\n",
       " [497, 0.9842866514667236],\n",
       " [498, 0.9997453966049434],\n",
       " [499, 0.9986285864280013],\n",
       " [500, 0.9991761569681333],\n",
       " [501, 0.9985218671625222],\n",
       " [502, 0.9250938173725272],\n",
       " [503, 0.42839600177123616],\n",
       " [504, 0.9767107614144969],\n",
       " [505, 0.9989605134378985],\n",
       " [506, 0.9251658847444741],\n",
       " [507, 0.9974388589118115],\n",
       " [508, 0.9908805873579611],\n",
       " [509, 0.9987656948271881],\n",
       " [510, 0.9386346068463481],\n",
       " [511, 0.9829741924913831],\n",
       " [512, 0.9864486763516982],\n",
       " [513, 0.9602834082668423],\n",
       " [514, 0.9966822401379891],\n",
       " [515, 0.9099061259319201],\n",
       " [516, 0.9929644958417285],\n",
       " [517, 0.9255341818466508],\n",
       " [518, 0.9753491840822109],\n",
       " [519, 0.9795812725507972],\n",
       " [520, 0.925202985917441],\n",
       " [521, 0.9963856606749177],\n",
       " [522, 0.9643127346721354],\n",
       " [523, 0.9361815066218423],\n",
       " [524, 0.9498170573743507],\n",
       " [525, 0.9882684485508086],\n",
       " [526, 0.9664198914362631],\n",
       " [527, 0.9940312228846333],\n",
       " [528, 0.955281460582088],\n",
       " [529, 0.9610839951849044],\n",
       " [530, 0.7998908973908974],\n",
       " [531, 0.983906637312411],\n",
       " [532, 0.9581378484612173],\n",
       " [533, 0.9250632629115423],\n",
       " [534, 0.9757121604043277],\n",
       " [535, 0.9784863765285404],\n",
       " [536, 0.9710265253295678],\n",
       " [537, 0.9052945895592422],\n",
       " [538, 0.9370456000087408],\n",
       " [539, 0.9847774648685818],\n",
       " [540, 0.994299030031266],\n",
       " [541, 0.9881869523300718],\n",
       " [542, 0.8169773872898874],\n",
       " [543, 0.9427500703986447],\n",
       " [544, 0.9684459831762677],\n",
       " [545, 0.9208140916750673],\n",
       " [546, 0.9945238874022762],\n",
       " [547, 0.9414147370327661],\n",
       " [548, 0.9635988086945083],\n",
       " [549, 0.9812309707889169],\n",
       " [550, 0.9948392116123717],\n",
       " [551, 0.2147442591748518],\n",
       " [552, 0.9859647300252643],\n",
       " [553, 0.9990078013332875],\n",
       " [554, 0.9964987580592576],\n",
       " [555, 0.9661734749719469],\n",
       " [556, 0.9718054298728852],\n",
       " [557, 0.9252435977935374],\n",
       " [558, 0.9934853586993977],\n",
       " [559, 0.9859380239800691],\n",
       " [560, 0.9740133594125633],\n",
       " [561, 0.9200377409624592],\n",
       " [562, 0.9984557522561955],\n",
       " [563, 0.9979266437097344],\n",
       " [564, 0.9909108990606867],\n",
       " [565, 0.9670777422743566],\n",
       " [566, 0.9820183638069139],\n",
       " [567, 0.9713112635866089],\n",
       " [568, 0.93760558351202],\n",
       " [569, 0.971371995479464],\n",
       " [570, 0.9200377409624592],\n",
       " [571, 0.9723239603110692],\n",
       " [572, 0.9382155940608337],\n",
       " [573, 0.9814051077259076],\n",
       " [574, 0.9875594453982446],\n",
       " [575, 0.9997872275072854],\n",
       " [576, 0.9200377409624592],\n",
       " [577, 0.9833947113713372],\n",
       " [578, 0.9972946077991347],\n",
       " [579, 0.9940982692719038],\n",
       " [580, 0.989932752899264],\n",
       " [581, 0.9835068510658184],\n",
       " [582, 0.9793442803045066],\n",
       " [583, 0.9724059559140272],\n",
       " [584, 0.9740133594125633],\n",
       " [585, 0.9743757136311384],\n",
       " [586, 0.9811411195258348],\n",
       " [587, 0.9298266270540261],\n",
       " [588, 0.9602590971221708],\n",
       " [589, 0.9949427679795487],\n",
       " [590, 0.9703386580291624],\n",
       " [591, 0.993968495290334],\n",
       " [592, 0.9793442803045066],\n",
       " [593, 0.9251768609467094],\n",
       " [594, 0.9722847218622055],\n",
       " [595, 0.9670560832905082],\n",
       " [596, 0.9681062895852598],\n",
       " [597, 0.8406189872315355],\n",
       " [598, 0.9971442950330045],\n",
       " [599, 0.9200377409624592],\n",
       " [600, 0.9778389024489822],\n",
       " [601, 0.9877069471714897],\n",
       " [602, 0.9771735573324243],\n",
       " [603, 0.9925058198554595],\n",
       " [604, 0.990269453492292],\n",
       " [605, 0.9200377409624592],\n",
       " [606, 0.9996173459154762],\n",
       " [607, 0.9684303461547655],\n",
       " [608, 0.9170951078074591],\n",
       " [609, 0.968219777456573],\n",
       " [610, 0.9232567215457677],\n",
       " [611, 0.9755496419948109],\n",
       " [612, 0.971280404287179],\n",
       " [613, 0.9481960000458786],\n",
       " [614, 0.997228781228156],\n",
       " [615, 0.9974971343262989],\n",
       " [616, 0.9998508594533781],\n",
       " [617, 0.9784734404294074],\n",
       " [618, 0.9684163725923464],\n",
       " [619, 0.974420747221352],\n",
       " [620, 0.9913291746390855],\n",
       " [621, 0.9701475604072842],\n",
       " [622, 0.885562629689114],\n",
       " [623, 0.8385938225460574],\n",
       " [624, 0.986546034863173],\n",
       " [625, 0.9755222787531203],\n",
       " [626, 0.9909348874263284],\n",
       " [627, 0.9536092805909551],\n",
       " [628, 0.9254225839880469],\n",
       " [629, 0.992410068815078],\n",
       " [630, 0.9973393334678351],\n",
       " [631, 0.9939235087705549],\n",
       " [632, 0.9200377409624592],\n",
       " [633, 0.9200377409624592],\n",
       " [634, 0.9599289214254693],\n",
       " [635, 0.9826196505324729],\n",
       " [636, 0.9200377409624592],\n",
       " [637, 0.9309966006611987],\n",
       " [638, 0.9881973629255627],\n",
       " [639, 0.9972982358621862],\n",
       " [640, 0.9917312682747357],\n",
       " [641, 0.9075194866311376],\n",
       " [642, 0.21476944604761777],\n",
       " [643, 0.9925739204742967],\n",
       " [644, 0.9901760885154847],\n",
       " [645, 0.9958104901852861],\n",
       " [646, 0.9250089223703695],\n",
       " [647, 0.9489257541493975],\n",
       " [648, 0.9994733087172492],\n",
       " [649, 0.98441795014148],\n",
       " [650, 0.9982388355444389],\n",
       " [651, 0.9515550950517835],\n",
       " [652, 0.9633006848410277],\n",
       " [653, 0.9831884665949702],\n",
       " [654, 0.995024997908472],\n",
       " [655, 0.973552325153652],\n",
       " [656, 0.6067163966488728],\n",
       " [657, 0.9997127732189319],\n",
       " [658, 0.9736051152043247],\n",
       " [659, 0.9588387090679381],\n",
       " [660, 0.9820124801971032],\n",
       " [661, 0.8912145773770543],\n",
       " [662, 0.9200377409624592],\n",
       " [663, 0.9317240215020923],\n",
       " [664, 0.9777531115903102],\n",
       " [665, 0.9134319083771544],\n",
       " [666, 0.9933783439199937],\n",
       " [667, 0.9635896315737528],\n",
       " [668, 0.9995652201093405],\n",
       " [669, 0.9755251115222585],\n",
       " [670, 0.9806364503882288],\n",
       " [671, 0.9957738085019123],\n",
       " [672, 0.9317006000790112],\n",
       " [673, 0.9517572818091136],\n",
       " [674, 0.9581991248899968],\n",
       " [675, 0.9793486118430914],\n",
       " [676, 0.9370456000087408],\n",
       " [677, 0.9708520592346621],\n",
       " [678, 0.9850633137442621],\n",
       " [679, 0.9728162139027123],\n",
       " [680, 0.9450091320419945],\n",
       " [681, 0.8929647473941127],\n",
       " [682, 0.9823175468556652],\n",
       " [683, 0.989932752899264],\n",
       " [684, 0.0470213220196097],\n",
       " [685, 0.9200377409624592],\n",
       " [686, 0.9999097870127122],\n",
       " [687, 0.9996646915443002],\n",
       " [688, 0.9402672591192868],\n",
       " [689, 0.9994376810074425],\n",
       " [690, 0.9996481590443675],\n",
       " [691, 0.9915155543793848],\n",
       " [692, 0.9200377409624592],\n",
       " [693, 0.9622833948620787],\n",
       " [694, 0.9856060479403835],\n",
       " [695, 0.9997350611985661],\n",
       " [696, 0.959023051007357],\n",
       " [697, 0.9942892071643987],\n",
       " [698, 0.984179301704858],\n",
       " [699, 0.9438583670831375],\n",
       " [700, 0.984625654362285],\n",
       " [701, 0.9784976100823762],\n",
       " [702, 0.9860290938436689],\n",
       " [703, 0.974402363190128],\n",
       " [704, 0.963422239143342],\n",
       " [705, 0.9070313728021333],\n",
       " [706, 0.9400277382177359],\n",
       " [707, 0.9758787665113801],\n",
       " [708, 0.9200377409624592],\n",
       " [709, 0.9536485782527011],\n",
       " [710, 0.9200377409624592],\n",
       " [711, 0.8038812476422728],\n",
       " [712, 0.9901755241127352],\n",
       " [713, 0.44965407975827987],\n",
       " [714, 0.9932794406947727],\n",
       " [715, 0.9200377409624592],\n",
       " [716, 0.9200377409624592],\n",
       " [717, 0.9136544050744156],\n",
       " [718, 0.9450423755910793],\n",
       " [719, 0.941119321803642],\n",
       " [720, 0.9400345358370622],\n",
       " [721, 0.9721866894784613],\n",
       " [722, 0.9425979785909385],\n",
       " [723, 0.9918372431874565],\n",
       " [724, 0.9767394431621035],\n",
       " [725, 0.9998300509880232],\n",
       " [726, 0.969386050887066],\n",
       " [727, 0.9960908808436543],\n",
       " [728, 0.9858874605800928],\n",
       " [729, 0.9799050691681733],\n",
       " [730, 0.9753016806895836],\n",
       " [731, 0.9980000894587672],\n",
       " [732, 0.9575378310362541],\n",
       " [733, 0.9601021709386905],\n",
       " [734, 0.9687890708179377],\n",
       " [735, 0.9249879750110761],\n",
       " [736, 0.9839943094560587],\n",
       " [737, 0.9200377409624592],\n",
       " [738, 0.9401897933953567],\n",
       " [739, 0.9933589598864652],\n",
       " [740, 0.9957830201671248],\n",
       " [741, 0.9664006888400898],\n",
       " [742, 0.9493633668661575],\n",
       " [743, 0.8636354058367223],\n",
       " [744, 0.9200377409624592],\n",
       " [745, 0.9979606695662839],\n",
       " [746, 0.9968494245024788],\n",
       " [747, 0.9637751705333034],\n",
       " [748, 0.9200377409624592],\n",
       " [749, 0.9200377409624592],\n",
       " [750, 0.9175868414049442],\n",
       " [751, 0.9337011996865996],\n",
       " [752, 0.9988046783644844],\n",
       " [753, 0.9997127732189319],\n",
       " [754, 0.8860766799888447],\n",
       " [755, 0.998791123667807],\n",
       " [756, 0.9530402488976348],\n",
       " [757, 0.9991050043886703],\n",
       " [758, 0.9998335882525924],\n",
       " [759, 0.9493497290393226],\n",
       " [760, 0.9072947425750378],\n",
       " [761, 0.9414147370327661],\n",
       " [762, 0.9806364503882288],\n",
       " [763, 0.9615954592202064],\n",
       " [764, 0.9253678709890807],\n",
       " [765, 0.9634413657987541],\n",
       " [766, 0.9800633015333957],\n",
       " [767, 0.9983551261305103],\n",
       " [768, 0.9809377662882387],\n",
       " [769, 0.9727806743419884],\n",
       " [770, 0.9816250673555128],\n",
       " [771, 0.9200377409624592],\n",
       " [772, 0.9997777017093418],\n",
       " [773, 0.9627920543078019],\n",
       " [774, 0.9838668868853331],\n",
       " [775, 0.9200377409624592],\n",
       " [776, 0.9818902885247087],\n",
       " [777, 0.9950497571564508],\n",
       " [778, 0.9920899931758381],\n",
       " [779, 0.9853526331191524],\n",
       " [780, 0.9954834251588969],\n",
       " [781, 0.9975435623356252],\n",
       " [782, 0.966898669137322],\n",
       " [783, 0.9452100077991694],\n",
       " [784, 0.9245191495691978],\n",
       " [785, 0.9534755042308743],\n",
       " [786, 0.9823549731038896],\n",
       " [787, 0.9200377409624592],\n",
       " [788, 0.9957781109745557],\n",
       " [789, 0.9797914833753036],\n",
       " [790, 0.9901698586325672],\n",
       " [791, 0.9355644596365886],\n",
       " [792, 0.992290115664393],\n",
       " [793, 0.9414699241148968],\n",
       " [794, 0.9574699738389221],\n",
       " [795, 0.998975043611398],\n",
       " [796, 0.9200377409624592],\n",
       " [797, 0.9917159080049988],\n",
       " [798, 0.9754884567737223],\n",
       " [799, 0.9200377409624592],\n",
       " [800, 0.9843394466688423],\n",
       " [801, 0.9713294838360396],\n",
       " [802, 0.03598509375757531],\n",
       " [803, 0.01072282514290081],\n",
       " [804, 0.9863128975458062],\n",
       " [805, 0.9918057149205712],\n",
       " [806, 0.9945207395335778],\n",
       " [807, 0.9990579852463283],\n",
       " [808, 0.9974559086529935],\n",
       " [809, 0.998485853087342],\n",
       " [810, 0.9981135729522823],\n",
       " [811, 0.9927000118221336],\n",
       " [812, 0.9942461358535454],\n",
       " [813, 0.9971920253369351],\n",
       " [814, 0.9963222536285203],\n",
       " [815, 0.994787046859481],\n",
       " [816, 0.9921183043263898],\n",
       " [817, 0.9962418905337564],\n",
       " [818, 0.9914798797990683],\n",
       " [819, 0.9972799928661411],\n",
       " [820, 0.9962418905337564],\n",
       " [821, 0.9960375675855648],\n",
       " [822, 0.9933878170572992],\n",
       " [823, 0.996989407807962],\n",
       " [824, 0.9990579852463283],\n",
       " [825, 0.9984884390832753],\n",
       " [826, 0.9991028943010581],\n",
       " [827, 0.997186791993671],\n",
       " [828, 0.998401874861288],\n",
       " [829, 0.9657861891812273],\n",
       " [830, 0.9748043873109429],\n",
       " [831, 0.9974113849048667],\n",
       " [832, 0.9914798797990683],\n",
       " [833, 0.989028649056954],\n",
       " [834, 0.01300585498038874],\n",
       " [835, 0.99473199540904],\n",
       " [836, 0.1007395808294473],\n",
       " [837, 0.9915608751101995],\n",
       " [838, 0.9988680923865637],\n",
       " [839, 0.9942133751976018],\n",
       " [840, 0.029617043428833607],\n",
       " [841, 0.9902470148713451],\n",
       " [842, 0.9996980375884423],\n",
       " [843, 0.9966087950799574],\n",
       " [844, 0.9986080368542829],\n",
       " [845, 0.24937881062439599],\n",
       " [846, 0.9964211845982293],\n",
       " [847, 0.9968585514256375],\n",
       " [848, 0.04656550759553968],\n",
       " [849, 0.9996980375884423],\n",
       " [850, 0.9932701718166518],\n",
       " [851, 0.9990579852463283],\n",
       " [852, 0.9965189376374021],\n",
       " [853, 0.9945448705002373],\n",
       " [854, 0.9942867151064515],\n",
       " [855, 0.9971920253369351],\n",
       " [856, 0.9962418905337564],\n",
       " [857, 0.9918876833373892],\n",
       " [858, 0.9975894139831363],\n",
       " [859, 0.9622175169485379],\n",
       " [860, 0.9906137647358865],\n",
       " [861, 0.9935133667671847],\n",
       " [862, 0.9891013866968287],\n",
       " [863, 0.9403572549939616],\n",
       " [864, 0.9985755235761345],\n",
       " [865, 0.9961431794544102],\n",
       " [866, 0.9983839668448663],\n",
       " [867, 0.9964106516502407],\n",
       " [868, 0.2802947929246413],\n",
       " [869, 0.995919572720176],\n",
       " [870, 0.9647943194276302],\n",
       " [871, 0.9991028943010581],\n",
       " [872, 0.9964789941982177],\n",
       " [873, 0.9969720856060492],\n",
       " [874, 0.9987100807476231],\n",
       " [875, 0.9859183998166966],\n",
       " [876, 0.9953215881647035],\n",
       " [877, 0.06857189661940905],\n",
       " [878, 0.9973853387884333],\n",
       " [879, 0.9988680923865637],\n",
       " [880, 0.9966104876822145],\n",
       " [881, 0.9966580377485383],\n",
       " [882, 0.8443803844824789],\n",
       " [883, 0.9953215881647035],\n",
       " [884, 0.9981135729522823],\n",
       " [885, 0.9962418905337564],\n",
       " [886, 0.9959371771506627],\n",
       " [887, 0.7145648144701715],\n",
       " [888, 0.9939880798286067],\n",
       " [889, 0.9931162553363293],\n",
       " [890, 0.5870696026273942],\n",
       " [891, 0.9918704897006922],\n",
       " [892, 0.9961527223420642],\n",
       " [893, 0.9990389059216648],\n",
       " [894, 0.9956559716730895],\n",
       " [895, 0.9955911361698936],\n",
       " [896, 0.9984884390832753],\n",
       " [897, 0.9913716546908431],\n",
       " [898, 0.9971920253369351],\n",
       " [899, 0.9972928220490479],\n",
       " [900, 0.9697091993586122],\n",
       " [901, 0.9891948632488372],\n",
       " [902, 0.9963731515495603],\n",
       " [903, 0.9928380560151007],\n",
       " [904, 0.9952781278143981],\n",
       " [905, 0.9954672895266871],\n",
       " [906, 0.9953215881647035],\n",
       " [907, 0.966518789913828],\n",
       " [908, 0.8443803844824789],\n",
       " [909, 0.9987923873134198],\n",
       " [910, 0.994562685794844],\n",
       " [911, 0.9985196226687225],\n",
       " [912, 0.8227509072591008],\n",
       " [913, 0.9936362382978359],\n",
       " [914, 0.9910489870544495],\n",
       " [915, 0.9957820932752774],\n",
       " [916, 0.9985908309011264],\n",
       " [917, 0.9905698540072908],\n",
       " [918, 0.9929462811233257],\n",
       " [919, 0.9966149307239478],\n",
       " [920, 0.9962418905337564],\n",
       " [921, 0.9984176387007393],\n",
       " [922, 0.06073242305212319],\n",
       " [923, 0.9847837337087455],\n",
       " [924, 0.008250620817301208],\n",
       " [925, 0.9969786526926432],\n",
       " [926, 0.9981188456673348],\n",
       " [927, 0.9971920253369351],\n",
       " [928, 0.00441367303497592],\n",
       " [929, 0.9649961230510942],\n",
       " [930, 0.9981953606992955],\n",
       " [931, 0.9988680923865637],\n",
       " [932, 0.9965917752148309],\n",
       " [933, 0.9948370374258468],\n",
       " [934, 0.9981135729522823],\n",
       " [935, 0.9981313507509946],\n",
       " [936, 0.9988229481041667],\n",
       " [937, 0.9939873369919899],\n",
       " [938, 0.9942825592150655],\n",
       " [939, 0.9943021364201892],\n",
       " [940, 0.9579389057843375],\n",
       " [941, 0.9936362382978359],\n",
       " [942, 0.9953252904822107],\n",
       " [943, 0.9482851755698016],\n",
       " [944, 0.9986080368542829],\n",
       " [945, 0.03853106264017786],\n",
       " [946, 0.30775939542483666],\n",
       " [947, 0.9985196226687225],\n",
       " [948, 0.050279875372462854],\n",
       " [949, 0.9971700029598727],\n",
       " [950, 0.9980017809334836],\n",
       " [951, 0.981699061072462],\n",
       " [952, 0.9953215881647035],\n",
       " [953, 0.9962418905337564],\n",
       " [954, 0.9676046238772787],\n",
       " [955, 0.9956254303536983],\n",
       " [956, 0.8443803844824789],\n",
       " [957, 0.9960375675855648],\n",
       " [958, 0.9962139811652193],\n",
       " [959, 0.9960368759129736],\n",
       " [960, 0.9906137647358865],\n",
       " [961, 0.9985582075126352],\n",
       " [962, 0.9981645411197503],\n",
       " [963, 0.9919784283020391],\n",
       " [964, 0.9974894734077238],\n",
       " [965, 0.998346514883243],\n",
       " [966, 0.9952794474659721],\n",
       " [967, 0.9920830505199897],\n",
       " [968, 0.9930208293834772],\n",
       " [969, 0.9991028943010581],\n",
       " [970, 0.9968608261972964],\n",
       " [971, 0.9964514543946341],\n",
       " [972, 0.9996980375884423],\n",
       " [973, 0.9955524587295035],\n",
       " [974, 0.9985582075126352],\n",
       " [975, 0.9984884390832753],\n",
       " [976, 0.9861893297654394],\n",
       " [977, 0.9953215881647035],\n",
       " [978, 0.9910637748616494],\n",
       " [979, 0.9482872856849097],\n",
       " [980, 0.9954193111299917],\n",
       " [981, 0.9967968943483119],\n",
       " [982, 0.9971984258454445],\n",
       " [983, 0.9922899340949826],\n",
       " [984, 0.994527963357902],\n",
       " [985, 0.9956748123729998],\n",
       " [986, 0.2744642898053039],\n",
       " [987, 0.9962418905337564],\n",
       " [988, 0.8227509072591008],\n",
       " [989, 0.995048265468825],\n",
       " [990, 0.013085697386762882],\n",
       " [991, 0.9991028943010581],\n",
       " [992, 0.9956172965791726],\n",
       " [993, 0.9973083171766742],\n",
       " [994, 0.9985582075126352],\n",
       " [995, 0.9981509033380188],\n",
       " [996, 0.946278976755378],\n",
       " [997, 0.991724456300952],\n",
       " [998, 0.9954672895266871],\n",
       " [999, 0.9953215881647035],\n",
       " ...]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_output('combined_best_tries__no_reassignment.csv',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
