{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition Development Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import unicodedata as ud\n",
    "import csv\n",
    "import random\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the vocab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab():\n",
    "    with open('vocab.csv') as file:\n",
    "        reader = csv.reader(file)\n",
    "        vocab = list(reader)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep training data for N Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(filename, N):\n",
    "    pre_string = \"<s>\"\n",
    "    post_string = \"</s>\"\n",
    "    train_dat = []\n",
    "        \n",
    "    with open(filename, encoding=\"utf8\") as file:\n",
    "        for line in file:\n",
    "            line = ud.normalize(\"NFC\",line)\n",
    "            line = re.sub('[–*:&()?@#!/,.\"“”]','',line)\n",
    "            line = re.sub('\\s+',' ',line)\n",
    "            line = line.lower()\n",
    "            split_line = line.strip().split()\n",
    "            for gram in range(1,N):\n",
    "                split_line.insert(0,pre_string)\n",
    "                split_line.append(post_string)\n",
    "            train_dat.append(split_line)\n",
    "    \n",
    "    return train_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a test example from a training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_example(training_line,word):\n",
    "    if \" \" + word[0] + \" \" in training_line:\n",
    "        new_str = ' {'+word[0]+\"|\"+word[1] + '} '\n",
    "        test_line = re.sub(\" \" + word[0] + \" \",new_str, training_line,1)\n",
    "        test_line = re.sub(\"<s>\",\"\",test_line)\n",
    "        test_line = re.sub(\"</s>\",\"\",test_line)\n",
    "        prob = 1\n",
    "        return test_line.strip(),prob\n",
    "    elif \" \" + word[1] + \" \" in training_line:\n",
    "        new_str = ' {'+word[0]+\"|\"+word[1] + '} '\n",
    "        test_line = re.sub(\" \" + word[1] + \" \",new_str, training_line,1)\n",
    "        test_line = re.sub(\"<s>\",\"\",test_line)\n",
    "        test_line = re.sub(\"</s>\",\"\",test_line)\n",
    "        prob = 0\n",
    "        return test_line.strip(),prob\n",
    "    else:\n",
    "        print(\"Error, word not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine which vocab word corresponds to location in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_vocab(index):\n",
    "    if index < 24200:\n",
    "        return 0, 24200\n",
    "    elif index < 48400:\n",
    "        return 1, 24200\n",
    "    elif index < 51290:\n",
    "        return 2, 2890\n",
    "    elif index < 75490:\n",
    "        return 3, 24200\n",
    "    elif index < 99690:\n",
    "        return 4, 24200\n",
    "    elif index < 123890:\n",
    "        return 5, 24200\n",
    "    elif index < 131159:\n",
    "        return 6, 7269\n",
    "    elif index < 155359:\n",
    "        return 7, 24200\n",
    "    elif index < 179559:\n",
    "        return 8, 24200\n",
    "    elif index < 203759:\n",
    "        return 9, 24200\n",
    "    elif index < 227959:\n",
    "        return 10, 24200\n",
    "    elif index < 252159:\n",
    "        return 11, 24200\n",
    "    elif index < 258227:\n",
    "        return 12, 6068\n",
    "    elif index < 282427:\n",
    "        return 13, 24200\n",
    "    elif index < 306627:\n",
    "        return 14, 24200\n",
    "    elif index < 310023:\n",
    "        return 15, 3396\n",
    "    elif index < 334223:\n",
    "        return 16, 24200\n",
    "    elif index < 358423:\n",
    "        return 17, 24200\n",
    "    elif index < 382623:\n",
    "        return 18, 24200\n",
    "    elif index < 406823:\n",
    "        return 19, 24200\n",
    "    elif index < 418928:\n",
    "        return 20, 12105\n",
    "    elif index < 430425:\n",
    "        return 21, 11497\n",
    "    elif index < 446988:\n",
    "        return 22, 16563\n",
    "    elif index < 452037:\n",
    "        return 23, 5049\n",
    "    elif index < 456571:\n",
    "        return 24, 4534"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and development\n",
    "#### Dev is saved to file, along with dev answers, new training array is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_split(train_array, percent_split, vocab_df, dev_filename, answers_filename):\n",
    "    dev_file = open(dev_filename,'w',encoding='utf8')\n",
    "    dev_answers = open(answers_filename,'w',encoding='utf8')\n",
    "    dev_answers.write(\"Id,Expected\\n\")\n",
    "    new_train = []\n",
    "\n",
    "    count = 1\n",
    "    vocab_word = 0\n",
    "    for index,training_line in enumerate(train_array):\n",
    "        vocab_word, vocab_count = which_vocab(index)  \n",
    "        if random.random() < percent_split/100:\n",
    "            test_line, prob = create_test_example(\" \".join(training_line),vocab_df[vocab_word])\n",
    "            dev_answers.write(str(count) + \",\" + str(prob) + \"\\n\")\n",
    "            dev_file.write(test_line + \"\\n\")\n",
    "            count += 1\n",
    "        else:\n",
    "            new_train.append(training_line)\n",
    "        \n",
    "    dev_file.close()\n",
    "    dev_answers.close()\n",
    "    \n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract N-gram choices from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(filename, N):\n",
    "    choices=[]\n",
    "    reg_exp_str = '\\{(.*)\\|(.*)\\}'\n",
    "    pre_string = ''\n",
    "    post_string = ''\n",
    "    for gram in range(1,N):\n",
    "        pre_string += '<s> '\n",
    "        post_string += ' </s>'\n",
    "        if gram % 2 == 0:\n",
    "            reg_exp_str = reg_exp_str + ' ([^ ]+)'\n",
    "        else:\n",
    "            reg_exp_str = '([^ ]+) ' + reg_exp_str\n",
    "    \n",
    "    reg_exp = re.compile(reg_exp_str)\n",
    "    with open(filename, encoding=\"utf8\") as file:\n",
    "        for row in file:\n",
    "            row = ud.normalize(\"NFC\",row)\n",
    "            row = re.sub('[–*:&()?@#!/,.\"“”]','',row)\n",
    "            row = re.sub('\\s+',' ',row)\n",
    "            row = row.lower()\n",
    "            row = pre_string + row.strip() + post_string\n",
    "            #extract options\n",
    "            match = reg_exp.search(row)\n",
    "            if match:\n",
    "                if N%2 ==0:\n",
    "                    midpoint = math.ceil((N+2)/2)\n",
    "                else:\n",
    "                    midpoint = math.ceil(N/2)\n",
    "                choice_1 = match.group(midpoint)\n",
    "                #print(choice_1)\n",
    "                choice_2 = match.group(midpoint+1)\n",
    "                #print(choice_2)\n",
    "                for match_group in range(midpoint+2,N+2):\n",
    "                    choice_1 += ' ' + match.group(match_group)\n",
    "                    choice_2 += ' ' + match.group(match_group)\n",
    "                for match_group in range(midpoint-1,0,-1):\n",
    "                    choice_1 = match.group(match_group) + ' ' + choice_1\n",
    "                    choice_2 = match.group(match_group) + ' ' + choice_2\n",
    "                choice = (choice_1, choice_2)\n",
    "            else:\n",
    "                print('error, no value')\n",
    "                print(reg_exp,\" \",row)\n",
    "                choice = 'error'\n",
    "            choices.append(choice)\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually create the dictionary with all n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, N):\n",
    "    model = {}\n",
    "    for line in train_data:\n",
    "        for each_N in range(1,N+1):\n",
    "            #for each line, generate all ngrams\n",
    "            for index in range(0,len(line)-each_N):\n",
    "                ngram = line[index]\n",
    "                for n_forward in range(1,each_N):\n",
    "                    ngram += ' ' + line[index+n_forward]\n",
    "                if ngram in model:\n",
    "                    model[ngram] += 1\n",
    "                else:\n",
    "                    model[ngram] = 1\n",
    "    return model            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepare_data('train.txt',3)\n",
    "model =train_model(train,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability function to determine likelihood of option_1 and option_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_probability(option_1,option_2,model):\n",
    "    if option_1 in model:\n",
    "        count_1 = model[option_1]\n",
    "    else:\n",
    "        count_1 = 0\n",
    "        \n",
    "    if option_2 in model:\n",
    "        count_2 = model[option_2]\n",
    "    else:\n",
    "        count_2 = 0\n",
    "        \n",
    "    if count_1 == 0 and count_2 == 0:\n",
    "        count_1 = 1\n",
    "        count_2 = 1    \n",
    "    elif count_1 == 0:\n",
    "        count_1 = .1\n",
    "    elif count_2 == 0:\n",
    "        count_2 = .1\n",
    "        \n",
    "    prob_1 = count_1/(count_1+count_2)\n",
    "    prob_2 = count_2/(count_1+count_2)\n",
    "    \n",
    "    return prob_1, prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backoff_probability(option_1,option_2,model):\n",
    "    if option_1 in model:\n",
    "        count_1 = model[option_1]\n",
    "    else:\n",
    "        count_1 = 0\n",
    "        \n",
    "    if option_2 in model:\n",
    "        count_2 = model[option_2]\n",
    "    else:\n",
    "        count_2 = 0\n",
    "    \n",
    "    if count_1 == 0 and count_2 == 0:\n",
    "        split_1 = option_1.split()\n",
    "        split_2 = option_2.split()\n",
    "        if len(split_1) > 1 and len(split_2) > 1:\n",
    "            if len(split_1) % 2 ==0:\n",
    "                split_1.pop(0)\n",
    "                split_2.pop(0)\n",
    "            else:\n",
    "                split_1.pop()\n",
    "                split_2.pop()\n",
    "            new_option_1 = \" \".join(split_1)\n",
    "            new_option_2 = \" \".join(split_2)\n",
    "            return backoff_probability(new_option_1,new_option_2,model)\n",
    "            \n",
    "    elif count_1 == 0:\n",
    "        count_1 = .1\n",
    "    elif count_2 == 0:\n",
    "        count_2 = .1\n",
    "        \n",
    "    prob_1 = count_1/(count_1+count_2)\n",
    "    prob_2 = count_2/(count_1+count_2)\n",
    "    \n",
    "    return prob_1, prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_probability(option_1,option_2,model,weight):\n",
    "    if option_1 in model:\n",
    "        count_1 = model[option_1]\n",
    "    else:\n",
    "        count_1 = 0\n",
    "        \n",
    "    if option_2 in model:\n",
    "        count_2 = model[option_2]\n",
    "    else:\n",
    "        count_2 = 0\n",
    "        \n",
    "    if count_1 == 0 and count_2 == 0:\n",
    "        count_1 = 1\n",
    "        count_2 = 1    \n",
    "    elif count_1 == 0:\n",
    "        count_1 = .1\n",
    "    elif count_2 == 0:\n",
    "        count_2 = .1\n",
    "        \n",
    "    prob_1 = count_1/(count_1+count_2) *weight\n",
    "    prob_2 = count_2/(count_1+count_2) *weight\n",
    "    \n",
    "    return prob_1, prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_probability(option_1,option_2,model,weights):\n",
    "    prob_1_arr=[]\n",
    "    prob_2_arr=[]\n",
    "    n_option_1 = option_1\n",
    "    n_option_2 = option_2\n",
    "    \n",
    "    while True:\n",
    "        # get basic probabilty and add to overall\n",
    "        c_prob_1, c_prob_2 = backoff_probability(n_option_1,n_option_2,model)\n",
    "        #c_prob_1, c_prob_2 = basic_probability(n_option_1,n_option_2,model)\n",
    "        prob_1_arr.append(c_prob_1)\n",
    "        prob_2_arr.append(c_prob_2)\n",
    "        \n",
    "        # split the options\n",
    "        split_1 = n_option_1.split()\n",
    "        split_2 = n_option_2.split()\n",
    "        \n",
    "        #get option lengths\n",
    "        len_1 = len(split_1)\n",
    "        len_2 = len(split_2)\n",
    "        \n",
    "        if len_1 <= 1 or len_2 <= 1:\n",
    "            break\n",
    "        \n",
    "        if len(split_1) % 2 ==0:\n",
    "            split_1.pop(0)\n",
    "            split_2.pop(0)\n",
    "        else:\n",
    "            split_1.pop()\n",
    "            split_2.pop()\n",
    "        n_option_1 = \" \".join(split_1)\n",
    "        n_option_2 = \" \".join(split_2)   \n",
    "    \n",
    "    #multiply probabilities by weights\n",
    "    prob_1 = np.dot(weights,prob_1_arr)\n",
    "    prob_2 = np.dot(weights,prob_2_arr)\n",
    "    \n",
    "    return prob_1, prob_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# prob = interpolate_probability(choices[4937][0],choices[4937][1],model,[.1,.9,0])\n",
    "# end = time.time()\n",
    "# print(end-start, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected_runtime = (end-start)*20000\n",
    "#expected_runtime/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ada_boost(train):\n",
    "#     train_data = prepare_data(train,N)\n",
    "#     vocab = create_vocab()\n",
    "#     new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "#     choices = prepare_test_data(dev_test,N)\n",
    "    \n",
    "#     results_array = []\n",
    "#     #initialize weights\n",
    "#     weights = []\n",
    "#     for x in range(0,len(train)):\n",
    "#         weights.append(1/len(train))\n",
    "        \n",
    "#     for trial in range(0,K):\n",
    "#         #train unigram with weights\n",
    "#         model = train_model(new_train,N)\n",
    "#         results = evaluate_weighted_model(model,choices,weights)\n",
    "#         results_array.append(results)\n",
    "#         success = write_output(output_name,results)\n",
    "#         score = evaluate_results(output_name,dev_answers)\n",
    "#         adaptive_param = 0.5*log((1-score)/score)\n",
    "#         weights = 1/Z * weights * exp(adaptive_param)\n",
    "        \n",
    "    \n",
    "#     train_data = prepare_data(train,N)\n",
    "#     vocab = create_vocab()\n",
    "#     new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "#     model = train_model(new_train,N)\n",
    "#     choices = prepare_test_data(dev_test,N)\n",
    "#     results = evaluate_interp_model(model,choices,weights)\n",
    "#     success = write_output(output_name,results)\n",
    "#     score = evaluate_results(output_name,dev_answers)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, choices):\n",
    "    results = [['Id','Expected']]\n",
    "    for index, choice in enumerate(choices):\n",
    "        c1,c2 = basic_probability(choice[0],choice[1],model)\n",
    "        results.append([index+1,c1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_backoff_model(model,choices):\n",
    "    results = [['Id','Expected']]\n",
    "    for index, choice in enumerate(choices):\n",
    "        c1,c2 = backoff_probability(choice[0],choice[1],model)\n",
    "        results.append([index+1,c1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_interp_model(model, choices, weights):\n",
    "    results = [['Id','Expected']]\n",
    "    for index, choice in enumerate(choices):\n",
    "        c1,c2 = interpolate_probability(choice[0],choice[1],model, weights)\n",
    "        results.append([index+1,c1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaulate_weighted_model(model, choices, weights):\n",
    "    results = [['Id','Expected']]\n",
    "    for index, choice in enumerate(choices):\n",
    "        c1,c2 = weighted_probability(choice[0],choice[1],model, weights[index])\n",
    "        results.append([index+1,c1])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write output to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(filename,results):\n",
    "    out_file = open(filename,'w')\n",
    "    count =0\n",
    "    for line in results:\n",
    "        output = str(line[0]) + \",\" + str(line[1]) + \"\\n\"\n",
    "        out_file.write(output)\n",
    "    out_file.close()\n",
    "    return 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare predictions to test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(prediction_file,actual_file):\n",
    "    with open(prediction_file) as file:\n",
    "        reader = csv.reader(file)\n",
    "        predictions = list(reader)\n",
    "    \n",
    "    with open(actual_file) as file:\n",
    "        reader = csv.reader(file)\n",
    "        actual = list(reader)\n",
    "    \n",
    "    if len(actual) != len(predictions):\n",
    "        print(\"Error: Files not the same length\")\n",
    "        return\n",
    "    \n",
    "    actual = np.array(actual)\n",
    "    actual = actual[1:,1].astype(np.float64)\n",
    "    predictions = np.array(predictions)\n",
    "    predictions = predictions[1:,1].astype(np.float64)\n",
    "    \n",
    "    log_loss_score = log_loss(actual, predictions, eps=1e-15)\n",
    "        \n",
    "    return log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_results(\"First_Dev_Test.csv\",\"dev_answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_pipeline(output_name,train,test,N):\n",
    "    train_data = prepare_data(train,N)\n",
    "    model = train_model(train_data,N)\n",
    "    choices = prepare_test_data(test,N)\n",
    "    results = evaluate_model(model,choices)\n",
    "    write_output(output_name,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_backoff_pipeline(output_name,train,test,N):\n",
    "    train_data = prepare_data(train,N)\n",
    "    model = train_model(train_data,N)\n",
    "    choices = prepare_test_data(test,N)\n",
    "    results = evaluate_backoff_model(model,choices)\n",
    "    write_output(output_name,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_interp_pipeline(output_name,train,test,N,weights):\n",
    "    train_data = prepare_data(train,N)\n",
    "    model = train_model(train_data,N)\n",
    "    choices = prepare_test_data(test,N)\n",
    "    results = evaluate_interp_model(model,choices,weights)\n",
    "    write_output(output_name,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_pipeline(\"trigram_with_bold_reassignment.csv\",\"train.txt\",\"test.txt\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_interp_pipeline(\"optimized_weight_hexagram.csv\",\"train.txt\",\"test.txt\",6,[0, 0.1, 0.1, .7, .1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Development Pipeline to Train model and get scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With basic probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_dev_basic_pipeline(output_name,train,dev_test,dev_answers,N,percent_split):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    model = train_model(new_train,N)\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    results = evaluate_model(model,choices)\n",
    "    success = write_output(output_name,results)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_prob_score = full_dev_basic_pipeline(\"basic_dev.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21733825302325682\n"
     ]
    }
   ],
   "source": [
    "print(basic_prob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_dev_pipeline(output_name,train,dev_test,dev_answers,N,percent_split,weights):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    model = train_model(new_train,N)\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    results = evaluate_interp_model(model,choices,weights)\n",
    "    success = write_output(output_name,results)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_dev_backoff_pipeline(output_name,train,dev_test,dev_answers,N,percent_split):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    model = train_model(new_train,N)\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    results = evaluate_backoff_model(model,choices)\n",
    "    success = write_output(output_name,results)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "backoff_prob_score = full_dev_backoff_pipeline(\"backoff_dev.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19763851595243404\n"
     ]
    }
   ],
   "source": [
    "print(backoff_prob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "backoff_prob_score = full_dev_backoff_pipeline(\"backoff_dev.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1634193353534091\n"
     ]
    }
   ],
   "source": [
    "print(backoff_prob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "backoff_prob_score = full_dev_backoff_pipeline(\"backoff_dev.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16997126864954332\n"
     ]
    }
   ],
   "source": [
    "print(backoff_prob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_score = full_dev_pipeline(\"interp_dev.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",4,10,[0.2, 0.7, 0.1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1663743322351299\n"
     ]
    }
   ],
   "source": [
    "print(interp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in np.arange(0,1.1,0.1):\n",
    "#     if x == 1:\n",
    "#         weights = [x,0,0]\n",
    "#         print(weights,full_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",3,10,weights))\n",
    "#     for y in np.arange (0,1.05-x,0.1):\n",
    "#         z = 1-y-x\n",
    "#         weights = [x,y,z]\n",
    "#         print(weights,full_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",3,10,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model,choices,output_name,dev_answers = half_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",5,10)\n",
    "# for x in np.arange(0.1,1.1,0.1):\n",
    "#     if x == 1:\n",
    "#         weights = [x,0,0,0,0]\n",
    "#         print(weights, rest_of_dev(model,choices,output_name,dev_answers,weights))\n",
    "#     for y in np.arange (0,1.05-x,0.1):\n",
    "#         if y ==1:\n",
    "#             weights = [0,y,0,0,0]\n",
    "#             print(weights,rest_of_dev(model,choices,output_name,dev_answers,weights))\n",
    "#         for z in np.arange(0,1.05-x-y,0.1):\n",
    "#             if z ==1:\n",
    "#                 weights = [0,0,z,0,0]\n",
    "#                 print(weights,rest_of_dev(model,choices,output_name,dev_answers,weights))\n",
    "#             for a in np.arange(0,1.05-x-y-z,0.1):\n",
    "#                 b = 1-x-y-z-a\n",
    "#                 weights = [x,y,z,a,b]\n",
    "#                 print(weights,rest_of_dev(model,choices,output_name,dev_answers,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",4,10,[0.2,0.7,0.1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_dev_pipeline(output_name,train,dev_test,dev_answers,N,percent_split):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    model = train_model(new_train,N)\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    return model,choices,output_name,dev_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_of_dev_interp(model,choices,output_name,dev_answers,weights):\n",
    "    results = evaluate_interp_model(model,choices,weights)\n",
    "    success = write_output(output_name,results)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_of_dev_backoff(model,choices,output_name,dev_answers,delta):\n",
    "    results = evaluate_backoff_model(model,choices,delta)\n",
    "    success = write_output(output_name,results)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_of_dev_basic(model,choices,output_name,dev_answers):\n",
    "    results = evaluate_backoff_model(model,choices,delta)\n",
    "    success = write_output(output_name,results)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,choices,output_name,dev_answers = half_dev_pipeline(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.2, .7, 0.1, 0]\n",
    "#weights = [.4, .6, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpo:  0.16426568463277524\n"
     ]
    }
   ],
   "source": [
    "#print(\"backoff: \",rest_of_dev_backoff(model,choices,output_name,dev_answers,1))\n",
    "print(\"interpo: \",rest_of_dev_interp(model,choices,output_name,dev_answers,weights))\n",
    "#print(\"basic: \",rest_of_dev_basic(model,choices,output_name,dev_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_resample(train_data):\n",
    "    train_size = len(train_data)\n",
    "    new_train = []\n",
    "    for x in range(0,len(train_data)):\n",
    "        new_train.append(train_data[math.floor(random.random()*train_size)])\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_test(output_name,train,dev_test,dev_answers,N,percent_split,weights,bags):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    new_train = train_dev_split(train_data, percent_split, vocab, dev_test, dev_answers)\n",
    "    overall_results_array = []\n",
    "    mean_array = [['ID','Expected']]\n",
    "    choices = prepare_test_data(dev_test,N)\n",
    "    for bag in range(0,bags):\n",
    "        bootstrapped_train = bootstrap_resample(new_train)\n",
    "        model = train_model(bootstrapped_train,N)\n",
    "        results = evaluate_interp_model(model,choices,weights)\n",
    "        overall_results_array.append(results)\n",
    "    for x in range(1,len(results)):\n",
    "        mean = 0\n",
    "        for result_array in overall_results_array:\n",
    "            mean += result_array[x][1]\n",
    "        mean = mean/len(overall_results_array)\n",
    "        mean_array.append([x,mean])\n",
    "    success = write_output(output_name,mean_array)\n",
    "    score = evaluate_results(output_name,dev_answers)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = bagging_test(\"a.csv\",\"train.txt\",\"dev_test.txt\",\"dev_answers.csv\",4,10,[.2, .7, .1, 0],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16990262608403892"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging_real(output_name,train,test,N,weights,bags):\n",
    "    train_data = prepare_data(train,N)\n",
    "    vocab = create_vocab()\n",
    "    overall_results_array = []\n",
    "    mean_array = [['ID','Expected']]\n",
    "    choices = prepare_test_data(test,N)\n",
    "    for bag in range(0,bags):\n",
    "        print(bag)\n",
    "        bootstrapped_train = bootstrap_resample(train_data)\n",
    "        model = train_model(bootstrapped_train,N)\n",
    "        results = evaluate_interp_model(model,choices,weights)\n",
    "        overall_results_array.append(results)\n",
    "    for x in range(1,len(results)):\n",
    "        mean = 0\n",
    "        for result_array in overall_results_array:\n",
    "            mean += result_array[x][1]\n",
    "        mean = mean/len(overall_results_array)\n",
    "        mean_array.append([x,mean])\n",
    "    success = write_output(output_name,mean_array)\n",
    "    return output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bagging_quad.csv'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_real(\"bagging_quad.csv\",\"train.txt\",\"test.txt\",4,[0.2,0.7,0.1,0],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_best_solutions(names):\n",
    "    all_predictions = []\n",
    "    mean_array = [['ID','Expected']]\n",
    "    pred_len = 0\n",
    "    for name in names:\n",
    "        with open(name) as file:\n",
    "            reader = csv.reader(file)\n",
    "            predictions = list(reader)\n",
    "            all_predictions.append(predictions)\n",
    "            pred_len = len(predictions)\n",
    "    for x in range(1,pred_len):\n",
    "        mean = 0\n",
    "        for ind,pred_list in enumerate(all_predictions):\n",
    "            mean += float(pred_list[x][1])\n",
    "        mean = mean/len(all_predictions)\n",
    "        mean_array.append([x,mean])\n",
    "    \n",
    "    return mean_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['optimized_weight_hexagram.csv','it_was_the_wrong_index.csv','a_very_bold_trigram.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compile_best_solutions(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ID', 'Expected'],\n",
       " [1, 0.9902526772431731],\n",
       " [2, 0.9495254390449303],\n",
       " [3, 0.9411510586012839],\n",
       " [4, 0.9559690271916738],\n",
       " [5, 0.9658400650826944],\n",
       " [6, 0.9950842074229737],\n",
       " [7, 0.9389658603849961],\n",
       " [8, 0.9877266084817031],\n",
       " [9, 0.9870176006521195],\n",
       " [10, 0.9364079600423568],\n",
       " [11, 0.9766737176103147],\n",
       " [12, 0.9723840742544253],\n",
       " [13, 0.9506495490478244],\n",
       " [14, 0.9736946227633769],\n",
       " [15, 0.8839469367993612],\n",
       " [16, 0.9940421472112305],\n",
       " [17, 0.9799335029948293],\n",
       " [18, 0.2839716664019319],\n",
       " [19, 0.9560887692842396],\n",
       " [20, 0.9878330523390538],\n",
       " [21, 0.9799378921526468],\n",
       " [22, 0.9835057394802732],\n",
       " [23, 0.9740191527770645],\n",
       " [24, 0.9941199842399434],\n",
       " [25, 0.9946203553703828],\n",
       " [26, 0.5956591924601861],\n",
       " [27, 0.9821497610433632],\n",
       " [28, 0.9750474267279904],\n",
       " [29, 0.9355650514103656],\n",
       " [30, 0.9901492959492525],\n",
       " [31, 0.995169496393053],\n",
       " [32, 0.9331295227847091],\n",
       " [33, 0.9619179416051186],\n",
       " [34, 0.9923145361365213],\n",
       " [35, 0.982560911074112],\n",
       " [36, 0.9814080967484001],\n",
       " [37, 0.9904359379549644],\n",
       " [38, 0.9974046653084115],\n",
       " [39, 0.8270029956975545],\n",
       " [40, 0.9932275164327615],\n",
       " [41, 0.9981201202562632],\n",
       " [42, 0.9970697637673097],\n",
       " [43, 0.9863153421537131],\n",
       " [44, 0.9704828909453845],\n",
       " [45, 0.9803826543714566],\n",
       " [46, 0.9936900079860621],\n",
       " [47, 0.9869340973654476],\n",
       " [48, 0.9978084131883461],\n",
       " [49, 0.9368221117685276],\n",
       " [50, 0.9872517634214559],\n",
       " [51, 0.9007876242865384],\n",
       " [52, 0.9765830083512514],\n",
       " [53, 0.775263468491929],\n",
       " [54, 0.9617345673113945],\n",
       " [55, 0.9956211994281837],\n",
       " [56, 0.9909485047111054],\n",
       " [57, 0.9690516839794366],\n",
       " [58, 0.9756859997697166],\n",
       " [59, 0.9824723695274727],\n",
       " [60, 0.9846915266212736],\n",
       " [61, 0.9356140311845493],\n",
       " [62, 0.9357719570769651],\n",
       " [63, 0.8564333733394486],\n",
       " [64, 0.9383594501025797],\n",
       " [65, 0.39998598620484666],\n",
       " [66, 0.9784643384627136],\n",
       " [67, 0.9682607802929534],\n",
       " [68, 0.9684111848547734],\n",
       " [69, 0.6735557966575642],\n",
       " [70, 0.9948326552458245],\n",
       " [71, 0.9840478736252085],\n",
       " [72, 0.9761478083380325],\n",
       " [73, 0.9545513546157932],\n",
       " [74, 0.9672066056724805],\n",
       " [75, 0.9728797656398459],\n",
       " [76, 0.9858406580377328],\n",
       " [77, 0.9665814400213438],\n",
       " [78, 0.9618165584459026],\n",
       " [79, 0.9376225441603846],\n",
       " [80, 0.9956611778619493],\n",
       " [81, 0.9524023015581778],\n",
       " [82, 0.9699510491515828],\n",
       " [83, 0.944870649264531],\n",
       " [84, 0.9919063593838017],\n",
       " [85, 0.9745813838902221],\n",
       " [86, 0.9893928470761525],\n",
       " [87, 0.9349697062892156],\n",
       " [88, 0.9948033018860415],\n",
       " [89, 0.9971657017655192],\n",
       " [90, 0.9367902586659476],\n",
       " [91, 0.9975127473163742],\n",
       " [92, 0.9614588259677271],\n",
       " [93, 0.9940397449892183],\n",
       " [94, 0.9920791922174589],\n",
       " [95, 0.9362773307697941],\n",
       " [96, 0.9950698186650185],\n",
       " [97, 0.9744050960072664],\n",
       " [98, 0.9976583434614997],\n",
       " [99, 0.9699372211426637],\n",
       " [100, 0.9776155062502045],\n",
       " [101, 0.9934836968130009],\n",
       " [102, 0.9821574520294915],\n",
       " [103, 0.9718304164166764],\n",
       " [104, 0.9944695802956552],\n",
       " [105, 0.9884876996934086],\n",
       " [106, 0.9517965654166889],\n",
       " [107, 0.9918932655122212],\n",
       " [108, 0.9718639966177748],\n",
       " [109, 0.9922460549032746],\n",
       " [110, 0.99679770491963],\n",
       " [111, 0.9989454941108112],\n",
       " [112, 0.9399847697450343],\n",
       " [113, 0.9411808262069511],\n",
       " [114, 0.9377872801536712],\n",
       " [115, 0.9927885938328148],\n",
       " [116, 0.9806480586374428],\n",
       " [117, 0.9620932683198652],\n",
       " [118, 0.9878423917867106],\n",
       " [119, 0.8988219754827079],\n",
       " [120, 0.9698938855415661],\n",
       " [121, 0.9556503522785919],\n",
       " [122, 0.9841809344818863],\n",
       " [123, 0.8784917082261977],\n",
       " [124, 0.9556810286705287],\n",
       " [125, 0.9989506836733594],\n",
       " [126, 0.9908617817093678],\n",
       " [127, 0.9847843179110544],\n",
       " [128, 0.981813484887324],\n",
       " [129, 0.890291635491225],\n",
       " [130, 0.9792729201378991],\n",
       " [131, 0.9695326884401855],\n",
       " [132, 0.13102428487589288],\n",
       " [133, 0.9567780812660649],\n",
       " [134, 0.9909484880313896],\n",
       " [135, 0.9761969633025259],\n",
       " [136, 0.9774589262369929],\n",
       " [137, 0.9475934964248696],\n",
       " [138, 0.9988716096733757],\n",
       " [139, 0.968369706193856],\n",
       " [140, 0.9887647551203894],\n",
       " [141, 0.9852609665666936],\n",
       " [142, 0.9912843515409113],\n",
       " [143, 0.9820168740479304],\n",
       " [144, 0.974296605305649],\n",
       " [145, 0.9611433320297665],\n",
       " [146, 0.993592699226638],\n",
       " [147, 0.9979783974687414],\n",
       " [148, 0.9606316180986457],\n",
       " [149, 0.9742943543781296],\n",
       " [150, 0.9953438590948286],\n",
       " [151, 0.9922469128196053],\n",
       " [152, 0.9949188531491858],\n",
       " [153, 0.9634910272424176],\n",
       " [154, 0.974928872271383],\n",
       " [155, 0.9942047807786878],\n",
       " [156, 0.9449442836284266],\n",
       " [157, 0.9941045334734984],\n",
       " [158, 0.9724802034354889],\n",
       " [159, 0.9379105047113869],\n",
       " [160, 0.9414598034405272],\n",
       " [161, 0.9372249057432863],\n",
       " [162, 0.9732813893635631],\n",
       " [163, 0.9206993571724169],\n",
       " [164, 0.9890597843833931],\n",
       " [165, 0.993565329856203],\n",
       " [166, 0.993068224079818],\n",
       " [167, 0.9924083193428301],\n",
       " [168, 0.9665237001803365],\n",
       " [169, 0.9677853925437653],\n",
       " [170, 0.987453893004755],\n",
       " [171, 0.9925707486588525],\n",
       " [172, 0.9706144662954893],\n",
       " [173, 0.9904784691251486],\n",
       " [174, 0.9783547564517906],\n",
       " [175, 0.9927593027838665],\n",
       " [176, 0.9790814850426233],\n",
       " [177, 0.9665560247554023],\n",
       " [178, 0.9335317006671423],\n",
       " [179, 0.9866579412875969],\n",
       " [180, 0.984804845018726],\n",
       " [181, 0.99462132959271],\n",
       " [182, 0.9382260576030969],\n",
       " [183, 0.9913215126932512],\n",
       " [184, 0.952326333316253],\n",
       " [185, 0.943949597627202],\n",
       " [186, 0.978613433112134],\n",
       " [187, 0.9913820575392002],\n",
       " [188, 0.9403108233829958],\n",
       " [189, 0.9383817587708528],\n",
       " [190, 0.9939773931834134],\n",
       " [191, 0.9744467236505243],\n",
       " [192, 0.9871752578907159],\n",
       " [193, 0.95622917079482],\n",
       " [194, 0.9762014064014103],\n",
       " [195, 0.9880003353504611],\n",
       " [196, 0.9349035075801377],\n",
       " [197, 0.9947237119641922],\n",
       " [198, 0.9674712694493377],\n",
       " [199, 0.984453224334653],\n",
       " [200, 0.9887327446139023],\n",
       " [201, 0.9726465481316747],\n",
       " [202, 0.9655320364328946],\n",
       " [203, 0.9843096294791778],\n",
       " [204, 0.9905250989028048],\n",
       " [205, 0.9327856020076757],\n",
       " [206, 0.9908983656909601],\n",
       " [207, 0.9695294597783684],\n",
       " [208, 0.9779174193040449],\n",
       " [209, 0.992326064322438],\n",
       " [210, 0.9842139694475138],\n",
       " [211, 0.9885669080912969],\n",
       " [212, 0.9896877678831594],\n",
       " [213, 0.9355381917000852],\n",
       " [214, 0.7973703004013079],\n",
       " [215, 0.9734614531989348],\n",
       " [216, 0.993012930703468],\n",
       " [217, 0.9867100167523658],\n",
       " [218, 0.9380839887161926],\n",
       " [219, 0.9556380550078973],\n",
       " [220, 0.8873352802220794],\n",
       " [221, 0.9842365012345603],\n",
       " [222, 0.9362818459275132],\n",
       " [223, 0.9931888047430114],\n",
       " [224, 0.9541085105921384],\n",
       " [225, 0.9775444950781976],\n",
       " [226, 0.998508962125722],\n",
       " [227, 0.9804236544408994],\n",
       " [228, 0.9646411553820154],\n",
       " [229, 0.988392305205354],\n",
       " [230, 0.9845412842164155],\n",
       " [231, 0.8519330555160146],\n",
       " [232, 0.9626904708831336],\n",
       " [233, 0.975905161308051],\n",
       " [234, 0.9660218692499991],\n",
       " [235, 0.9756597757686416],\n",
       " [236, 0.989634068263909],\n",
       " [237, 0.9984944095209602],\n",
       " [238, 0.9743462666074377],\n",
       " [239, 0.9046024455451],\n",
       " [240, 0.992863181399999],\n",
       " [241, 0.9446151725870028],\n",
       " [242, 0.9371687289731535],\n",
       " [243, 0.9841137504279582],\n",
       " [244, 0.9599452245777593],\n",
       " [245, 0.9654700048377362],\n",
       " [246, 0.9868233441845425],\n",
       " [247, 0.9813165362288204],\n",
       " [248, 0.9967935375212656],\n",
       " [249, 0.9909541739873662],\n",
       " [250, 0.9430785979001195],\n",
       " [251, 0.9566764351400613],\n",
       " [252, 0.9907636896307496],\n",
       " [253, 0.9897141242185858],\n",
       " [254, 0.9882276317841675],\n",
       " [255, 0.9359065272666093],\n",
       " [256, 0.996381029844981],\n",
       " [257, 0.9693196395848643],\n",
       " [258, 0.9663357993724663],\n",
       " [259, 0.944250147052943],\n",
       " [260, 0.9835608786170624],\n",
       " [261, 0.996694752450209],\n",
       " [262, 0.9977267294505339],\n",
       " [263, 0.9657190695114964],\n",
       " [264, 0.9831830952022914],\n",
       " [265, 0.978186269111744],\n",
       " [266, 0.9971246641122525],\n",
       " [267, 0.983642010447392],\n",
       " [268, 0.9734991151504158],\n",
       " [269, 0.9828563938873507],\n",
       " [270, 0.9868905988646706],\n",
       " [271, 0.9779719076639747],\n",
       " [272, 0.9745973517661968],\n",
       " [273, 0.9853300834441684],\n",
       " [274, 0.9444700117597654],\n",
       " [275, 0.938800602354342],\n",
       " [276, 0.9706241129169325],\n",
       " [277, 0.989085629666426],\n",
       " [278, 0.960915010908686],\n",
       " [279, 0.9640290510771644],\n",
       " [280, 0.9930762147392732],\n",
       " [281, 0.9827217743981266],\n",
       " [282, 0.9678590210836986],\n",
       " [283, 0.9893544869021014],\n",
       " [284, 0.9731526063443118],\n",
       " [285, 0.9872489591278145],\n",
       " [286, 0.9375120130409975],\n",
       " [287, 0.844024341437473],\n",
       " [288, 0.9546448295750136],\n",
       " [289, 0.975416805174942],\n",
       " [290, 0.9811544572781554],\n",
       " [291, 0.9744366115762478],\n",
       " [292, 0.9797194873590603],\n",
       " [293, 0.9578821521058788],\n",
       " [294, 0.9892966972502727],\n",
       " [295, 0.8743422982976111],\n",
       " [296, 0.9720676187115261],\n",
       " [297, 0.9399438229495426],\n",
       " [298, 0.9880973620814243],\n",
       " [299, 0.2695733599320316],\n",
       " [300, 0.9557394910273057],\n",
       " [301, 0.9886640113181987],\n",
       " [302, 0.9852395497708158],\n",
       " [303, 0.9775441056781439],\n",
       " [304, 0.9155081249778801],\n",
       " [305, 0.9891449179344005],\n",
       " [306, 0.3615267060202512],\n",
       " [307, 0.9655862283032571],\n",
       " [308, 0.9888341303148201],\n",
       " [309, 0.974123667451252],\n",
       " [310, 0.9952972867948783],\n",
       " [311, 0.9894134821250521],\n",
       " [312, 0.9869680617277655],\n",
       " [313, 0.6322317908327476],\n",
       " [314, 0.9729083615961157],\n",
       " [315, 0.994479907010862],\n",
       " [316, 0.993522743759529],\n",
       " [317, 0.9275531748202805],\n",
       " [318, 0.9383977531626263],\n",
       " [319, 0.9802730301523984],\n",
       " [320, 0.9973267006526757],\n",
       " [321, 0.9373943859216216],\n",
       " [322, 0.939716795476543],\n",
       " [323, 0.9952970883092213],\n",
       " [324, 0.9814213634548534],\n",
       " [325, 0.855520200833627],\n",
       " [326, 0.9391727341080043],\n",
       " [327, 0.9847024078048981],\n",
       " [328, 0.9778624113423903],\n",
       " [329, 0.9261387432007889],\n",
       " [330, 0.7791971650977008],\n",
       " [331, 0.9815499339925494],\n",
       " [332, 0.9970620639523337],\n",
       " [333, 0.993943719796707],\n",
       " [334, 0.9787827640873683],\n",
       " [335, 0.885684641739756],\n",
       " [336, 0.9900037546741819],\n",
       " [337, 0.97018943410779],\n",
       " [338, 0.983679681415702],\n",
       " [339, 0.989409313472065],\n",
       " [340, 0.9826746312487945],\n",
       " [341, 0.9326381293071182],\n",
       " [342, 0.9851744366477554],\n",
       " [343, 0.9932318104648014],\n",
       " [344, 0.9537988470152775],\n",
       " [345, 0.9730827093613414],\n",
       " [346, 0.9724373909274169],\n",
       " [347, 0.6932356270961727],\n",
       " [348, 0.9469193115717921],\n",
       " [349, 0.9718403418984346],\n",
       " [350, 0.935954308666343],\n",
       " [351, 0.8688523837335804],\n",
       " [352, 0.9666813031951444],\n",
       " [353, 0.9951132989523552],\n",
       " [354, 0.9915352327761893],\n",
       " [355, 0.9843482725320962],\n",
       " [356, 0.9628695419635142],\n",
       " [357, 0.950146234282546],\n",
       " [358, 0.9821993699042365],\n",
       " [359, 0.9382401276855933],\n",
       " [360, 0.9783530334657861],\n",
       " [361, 0.9799885890725196],\n",
       " [362, 0.966929887292917],\n",
       " [363, 0.9968042066268632],\n",
       " [364, 0.9310639451610653],\n",
       " [365, 0.9905798694406759],\n",
       " [366, 0.9497431237865465],\n",
       " [367, 0.9943233833712317],\n",
       " [368, 0.9849245477941094],\n",
       " [369, 0.9725010346925963],\n",
       " [370, 0.9465713991299939],\n",
       " [371, 0.9951026396996555],\n",
       " [372, 0.9742702653444323],\n",
       " [373, 0.9887956207997114],\n",
       " [374, 0.9665360830146401],\n",
       " [375, 0.9730446292618146],\n",
       " [376, 0.9794734786546941],\n",
       " [377, 0.849841302170105],\n",
       " [378, 0.97274455264571],\n",
       " [379, 0.9952325567087076],\n",
       " [380, 0.9848880241685304],\n",
       " [381, 0.9738800786919852],\n",
       " [382, 0.9916280966306021],\n",
       " [383, 0.9919920861085111],\n",
       " [384, 0.9962101155172848],\n",
       " [385, 0.9847246246934286],\n",
       " [386, 0.939828976079311],\n",
       " [387, 0.965726494592643],\n",
       " [388, 0.9780072460542893],\n",
       " [389, 0.9391796577015685],\n",
       " [390, 0.9733520944231877],\n",
       " [391, 0.9513879221706185],\n",
       " [392, 0.978573117526291],\n",
       " [393, 0.9360121226855739],\n",
       " [394, 0.9676517424305825],\n",
       " [395, 0.9852866543597502],\n",
       " [396, 0.9621359550301545],\n",
       " [397, 0.9754738183301807],\n",
       " [398, 0.9958295903209708],\n",
       " [399, 0.9916217385224133],\n",
       " [400, 0.9961867853271942],\n",
       " [401, 0.9930170608852721],\n",
       " [402, 0.9604365656403925],\n",
       " [403, 0.9922000749841445],\n",
       " [404, 0.9887865394917735],\n",
       " [405, 0.9968099204774541],\n",
       " [406, 0.9241486912675483],\n",
       " [407, 0.9900408196549471],\n",
       " [408, 0.9920536342299466],\n",
       " [409, 0.9808008309080011],\n",
       " [410, 0.9734724420654549],\n",
       " [411, 0.9595003562664495],\n",
       " [412, 0.9759215622504018],\n",
       " [413, 0.9342716601802555],\n",
       " [414, 0.9779749924638462],\n",
       " [415, 0.9789595176553686],\n",
       " [416, 0.9796146279150423],\n",
       " [417, 0.9908689933595946],\n",
       " [418, 0.9834943214764015],\n",
       " [419, 0.9467543904840099],\n",
       " [420, 0.9053206943167692],\n",
       " [421, 0.9908652735348363],\n",
       " [422, 0.9946423628530209],\n",
       " [423, 0.9906853172059197],\n",
       " [424, 0.9943192640387585],\n",
       " [425, 0.9647992484496295],\n",
       " [426, 0.9582024685866974],\n",
       " [427, 0.9878397745550184],\n",
       " [428, 0.9764312057454658],\n",
       " [429, 0.9832032674341797],\n",
       " [430, 0.9516834598597536],\n",
       " [431, 0.9586122360103376],\n",
       " [432, 0.9870396173585383],\n",
       " [433, 0.9880329701575074],\n",
       " [434, 0.9604991172179553],\n",
       " [435, 0.9942633629693484],\n",
       " [436, 0.9973735625308531],\n",
       " [437, 0.9465748533919106],\n",
       " [438, 0.9958666374483668],\n",
       " [439, 0.9941047946961143],\n",
       " [440, 0.9841526005814772],\n",
       " [441, 0.9886268892778541],\n",
       " [442, 0.9831085340865173],\n",
       " [443, 0.9938166482855525],\n",
       " [444, 0.9961912124685893],\n",
       " [445, 0.9402806863566417],\n",
       " [446, 0.9330116620679808],\n",
       " [447, 0.9408198945877574],\n",
       " [448, 0.997421392481503],\n",
       " [449, 0.9663674240752326],\n",
       " [450, 0.9958776263643013],\n",
       " [451, 0.9705217905215417],\n",
       " [452, 0.9347108815501395],\n",
       " [453, 0.9629496596153789],\n",
       " [454, 0.9957194008594574],\n",
       " [455, 0.9967445933806302],\n",
       " [456, 0.9331562465849648],\n",
       " [457, 0.98796248141225],\n",
       " [458, 0.9706751348579528],\n",
       " [459, 0.9350515120334287],\n",
       " [460, 0.9370945371493287],\n",
       " [461, 0.9769257136000583],\n",
       " [462, 0.9346565007240414],\n",
       " [463, 0.9983026729002544],\n",
       " [464, 0.9948567067739877],\n",
       " [465, 0.9745659865965871],\n",
       " [466, 0.961965588549934],\n",
       " [467, 0.9976583434614997],\n",
       " [468, 0.9945807750732055],\n",
       " [469, 0.9831186662260093],\n",
       " [470, 0.9908539013321835],\n",
       " [471, 0.9819575587179666],\n",
       " [472, 0.991220732862236],\n",
       " [473, 0.9669022449902603],\n",
       " [474, 0.8412656596794849],\n",
       " [475, 0.939579160423394],\n",
       " [476, 0.964153768692721],\n",
       " [477, 0.9299406135781716],\n",
       " [478, 0.9373906666394342],\n",
       " [479, 0.9817571555491559],\n",
       " [480, 0.9921876888873845],\n",
       " [481, 0.9972336960096987],\n",
       " [482, 0.9891913697846877],\n",
       " [483, 0.9356208116240917],\n",
       " [484, 0.9978914237111861],\n",
       " [485, 0.9950023632787269],\n",
       " [486, 0.9716914594004663],\n",
       " [487, 0.9649697921501278],\n",
       " [488, 0.9740353097744595],\n",
       " [489, 0.896765447289439],\n",
       " [490, 0.984042118057528],\n",
       " [491, 0.9928379575166296],\n",
       " [492, 0.9722944983304568],\n",
       " [493, 0.9731462253402435],\n",
       " [494, 0.9324068488656083],\n",
       " [495, 0.9360059409980485],\n",
       " [496, 0.9069940246233431],\n",
       " [497, 0.9824584197111331],\n",
       " [498, 0.9926109754573108],\n",
       " [499, 0.9926594319512283],\n",
       " [500, 0.9963502058855611],\n",
       " [501, 0.96230105178371],\n",
       " [502, 0.9650697998974699],\n",
       " [503, 0.42626110599384326],\n",
       " [504, 0.9830887137582134],\n",
       " [505, 0.9834652879346946],\n",
       " [506, 0.9300476328311241],\n",
       " [507, 0.9900053651677716],\n",
       " [508, 0.9921998015652175],\n",
       " [509, 0.9964931576185609],\n",
       " [510, 0.9459516019697517],\n",
       " [511, 0.9671937884470921],\n",
       " [512, 0.9862312076765138],\n",
       " [513, 0.9669143013840961],\n",
       " [514, 0.9946742302238878],\n",
       " [515, 0.9342923018840024],\n",
       " [516, 0.9908678084536943],\n",
       " [517, 0.9340119448053487],\n",
       " [518, 0.9785423151049369],\n",
       " [519, 0.981291593845484],\n",
       " [520, 0.9595464597474405],\n",
       " [521, 0.9883950102094176],\n",
       " [522, 0.9750065278380146],\n",
       " [523, 0.972906166847101],\n",
       " [524, 0.9587971018750158],\n",
       " [525, 0.9861661932100177],\n",
       " [526, 0.9528532021086319],\n",
       " [527, 0.994249883120358],\n",
       " [528, 0.9617245553139485],\n",
       " [529, 0.9647696429273118],\n",
       " [530, 0.8642108873715394],\n",
       " [531, 0.9868499465278132],\n",
       " [532, 0.958764442621081],\n",
       " [533, 0.9369046222817913],\n",
       " [534, 0.982101043899508],\n",
       " [535, 0.9819266594503392],\n",
       " [536, 0.9776898683608767],\n",
       " [537, 0.920847052803361],\n",
       " [538, 0.9530828772240749],\n",
       " [539, 0.9873842065209925],\n",
       " [540, 0.9894497695778548],\n",
       " [541, 0.9870243700192276],\n",
       " [542, 0.8761759519420721],\n",
       " [543, 0.9495276916885311],\n",
       " [544, 0.9729935291228321],\n",
       " [545, 0.935950916590333],\n",
       " [546, 0.9895135879324556],\n",
       " [547, 0.9545014174601123],\n",
       " [548, 0.9636149931350166],\n",
       " [549, 0.9822878113528027],\n",
       " [550, 0.9913590242724593],\n",
       " [551, 0.2640485502888457],\n",
       " [552, 0.9902892782693099],\n",
       " [553, 0.99852607014909],\n",
       " [554, 0.9938546998303653],\n",
       " [555, 0.9212535934201574],\n",
       " [556, 0.9780394281784665],\n",
       " [557, 0.9366510988109583],\n",
       " [558, 0.9942408666424419],\n",
       " [559, 0.9750694746516196],\n",
       " [560, 0.9773388811170972],\n",
       " [561, 0.9717859582383926],\n",
       " [562, 0.9950568162333718],\n",
       " [563, 0.9963815441230549],\n",
       " [564, 0.9926959950435488],\n",
       " [565, 0.9748810244211726],\n",
       " [566, 0.9823967555664902],\n",
       " [567, 0.9802852369317078],\n",
       " [568, 0.938464566627412],\n",
       " [569, 0.9790990522248881],\n",
       " [570, 0.9732191162466931],\n",
       " [571, 0.9674007857305879],\n",
       " [572, 0.933299105254758],\n",
       " [573, 0.9889125914113963],\n",
       " [574, 0.9795655537007096],\n",
       " [575, 0.987621884401491],\n",
       " [576, 0.9566465975166712],\n",
       " [577, 0.9835065463796302],\n",
       " [578, 0.9903620626431725],\n",
       " [579, 0.9903259898744783],\n",
       " [580, 0.9874885930872782],\n",
       " [581, 0.9809922332275299],\n",
       " [582, 0.9774974438283305],\n",
       " [583, 0.9764314825342018],\n",
       " [584, 0.9725474617381153],\n",
       " [585, 0.9823005519032869],\n",
       " [586, 0.9788833991137315],\n",
       " [587, 0.9363626161191351],\n",
       " [588, 0.9681718801574569],\n",
       " [589, 0.9929009552661876],\n",
       " [590, 0.961789435707627],\n",
       " [591, 0.9945616293743643],\n",
       " [592, 0.9818944211171657],\n",
       " [593, 0.9330487628609229],\n",
       " [594, 0.9758693825123602],\n",
       " [595, 0.9651767514547863],\n",
       " [596, 0.9746788891226553],\n",
       " [597, 0.9388808451530012],\n",
       " [598, 0.9968200095473861],\n",
       " [599, 0.9744237626501416],\n",
       " [600, 0.9761811790121547],\n",
       " [601, 0.9887558612169677],\n",
       " [602, 0.9859137121728567],\n",
       " [603, 0.9961552786472705],\n",
       " [604, 0.9932285237759119],\n",
       " [605, 0.9721716760748489],\n",
       " [606, 0.9947180339520257],\n",
       " [607, 0.9809185663859288],\n",
       " [608, 0.9421577082212603],\n",
       " [609, 0.9743924046767724],\n",
       " [610, 0.9488663131344923],\n",
       " [611, 0.9765560521451445],\n",
       " [612, 0.9756348601439896],\n",
       " [613, 0.9374832106614907],\n",
       " [614, 0.9956619854433914],\n",
       " [615, 0.9957967734656107],\n",
       " [616, 0.997873009125481],\n",
       " [617, 0.982785310603918],\n",
       " [618, 0.9772994702972689],\n",
       " [619, 0.9753687288264589],\n",
       " [620, 0.9932118339374515],\n",
       " [621, 0.9677327036167425],\n",
       " [622, 0.9170019929032902],\n",
       " [623, 0.9274269318596944],\n",
       " [624, 0.985148502978577],\n",
       " [625, 0.979130558085734],\n",
       " [626, 0.9869047296677694],\n",
       " [627, 0.9615920242156116],\n",
       " [628, 0.9273844402661989],\n",
       " [629, 0.98972090841254],\n",
       " [630, 0.9926647381645121],\n",
       " [631, 0.9892425857963669],\n",
       " [632, 0.9736637436006929],\n",
       " [633, 0.9599329828411717],\n",
       " [634, 0.9665339678286266],\n",
       " [635, 0.9800701115291863],\n",
       " [636, 0.9634758526654036],\n",
       " [637, 0.947273848496859],\n",
       " [638, 0.9684947523847306],\n",
       " [639, 0.9889940899433064],\n",
       " [640, 0.9919692291708806],\n",
       " [641, 0.9367673459181812],\n",
       " [642, 0.23813001232308997],\n",
       " [643, 0.9915810579446308],\n",
       " [644, 0.9876307630008707],\n",
       " [645, 0.9947525310445325],\n",
       " [646, 0.9369386003194914],\n",
       " [647, 0.9578968105927345],\n",
       " [648, 0.9685113521408829],\n",
       " [649, 0.9889324487392314],\n",
       " [650, 0.9972147177621632],\n",
       " [651, 0.9594050576971346],\n",
       " [652, 0.9635390933170429],\n",
       " [653, 0.9841048633044629],\n",
       " [654, 0.9835398137575182],\n",
       " [655, 0.9854144143446972],\n",
       " [656, 0.5327116606398786],\n",
       " [657, 0.9971181325051286],\n",
       " [658, 0.9751344626509139],\n",
       " [659, 0.9630813344011601],\n",
       " [660, 0.987375523588644],\n",
       " [661, 0.9048299838342867],\n",
       " [662, 0.9734011646325689],\n",
       " [663, 0.949847629796975],\n",
       " [664, 0.9635571010914564],\n",
       " [665, 0.9241181543181245],\n",
       " [666, 0.9878191368670098],\n",
       " [667, 0.9688537047560825],\n",
       " [668, 0.9988574841531999],\n",
       " [669, 0.9775429240117176],\n",
       " [670, 0.9807257570210548],\n",
       " [671, 0.992242232880124],\n",
       " [672, 0.9494963282925353],\n",
       " [673, 0.9616888174869335],\n",
       " [674, 0.9702489563378486],\n",
       " [675, 0.9764548065879324],\n",
       " [676, 0.9532883387395351],\n",
       " [677, 0.973890995823736],\n",
       " [678, 0.9838331234886614],\n",
       " [679, 0.9762296628634006],\n",
       " [680, 0.9567264052657949],\n",
       " [681, 0.9245337855146718],\n",
       " [682, 0.9812235208324721],\n",
       " [683, 0.9897464584436237],\n",
       " [684, 0.2380967953785524],\n",
       " [685, 0.9703238538848793],\n",
       " [686, 0.9981683086481056],\n",
       " [687, 0.9984463212068375],\n",
       " [688, 0.9254334490369259],\n",
       " [689, 0.9924818048510362],\n",
       " [690, 0.9945323698679821],\n",
       " [691, 0.9957509638334322],\n",
       " [692, 0.9657120925729176],\n",
       " [693, 0.9669429155131266],\n",
       " [694, 0.9771388429058989],\n",
       " [695, 0.9971378953124287],\n",
       " [696, 0.9681533066301458],\n",
       " [697, 0.9829949530336313],\n",
       " [698, 0.9880437710814504],\n",
       " [699, 0.940039199598316],\n",
       " [700, 0.9888549947765286],\n",
       " [701, 0.9807919010276703],\n",
       " [702, 0.9877631868522935],\n",
       " [703, 0.9735910073344513],\n",
       " [704, 0.9668694552882823],\n",
       " [705, 0.9300867757284111],\n",
       " [706, 0.9381322856428734],\n",
       " [707, 0.9795379083223382],\n",
       " [708, 0.9713153864561107],\n",
       " [709, 0.9661171095251472],\n",
       " [710, 0.9686960715390285],\n",
       " [711, 0.8617058300134203],\n",
       " [712, 0.9865256679851809],\n",
       " [713, 0.4146195969906567],\n",
       " [714, 0.9936445896163094],\n",
       " [715, 0.9749030726473883],\n",
       " [716, 0.9659167949732096],\n",
       " [717, 0.929615369693633],\n",
       " [718, 0.939668173514702],\n",
       " [719, 0.9352317950561656],\n",
       " [720, 0.9347384722634189],\n",
       " [721, 0.9782983911781953],\n",
       " [722, 0.9386070626972834],\n",
       " [723, 0.9923726432683068],\n",
       " [724, 0.9807594314715163],\n",
       " [725, 0.9959684986028948],\n",
       " [726, 0.9709500011272157],\n",
       " [727, 0.9932358724965052],\n",
       " [728, 0.9818952656488941],\n",
       " [729, 0.9808176575050029],\n",
       " [730, 0.977862206510958],\n",
       " [731, 0.9971962593009471],\n",
       " [732, 0.9691050826744955],\n",
       " [733, 0.9676166178803073],\n",
       " [734, 0.9755346897035752],\n",
       " [735, 0.9256856586174571],\n",
       " [736, 0.9853732412225136],\n",
       " [737, 0.9736038138345929],\n",
       " [738, 0.9642872333490105],\n",
       " [739, 0.994724257654052],\n",
       " [740, 0.9807990825314911],\n",
       " [741, 0.9725415027980113],\n",
       " [742, 0.9583261240986228],\n",
       " [743, 0.8614139753256377],\n",
       " [744, 0.9654913111938997],\n",
       " [745, 0.9975417810703077],\n",
       " [746, 0.9963411269488812],\n",
       " [747, 0.9647046455227818],\n",
       " [748, 0.9671248065651916],\n",
       " [749, 0.966594703892164],\n",
       " [750, 0.9637290344592994],\n",
       " [751, 0.9723021947276398],\n",
       " [752, 0.9964193711679773],\n",
       " [753, 0.9971374190455046],\n",
       " [754, 0.913293736808139],\n",
       " [755, 0.9973567640346305],\n",
       " [756, 0.9648414488568617],\n",
       " [757, 0.9974798518703536],\n",
       " [758, 0.9984415331448084],\n",
       " [759, 0.9398665831251921],\n",
       " [760, 0.9115726966428098],\n",
       " [761, 0.953052569251871],\n",
       " [762, 0.9825327710201922],\n",
       " [763, 0.9674348677559675],\n",
       " [764, 0.9275285128501541],\n",
       " [765, 0.9721413377568652],\n",
       " [766, 0.9761408479232223],\n",
       " [767, 0.9934564781780165],\n",
       " [768, 0.9840768557223809],\n",
       " [769, 0.9855580556252113],\n",
       " [770, 0.9882800648787212],\n",
       " [771, 0.9260976613630758],\n",
       " [772, 0.9972592281601349],\n",
       " [773, 0.9827709625630767],\n",
       " [774, 0.9837749371772304],\n",
       " [775, 0.9734287002486811],\n",
       " [776, 0.9870205350899682],\n",
       " [777, 0.9961276373178283],\n",
       " [778, 0.9845219832313897],\n",
       " [779, 0.983253611100389],\n",
       " [780, 0.9898163771097547],\n",
       " [781, 0.9941495794263538],\n",
       " [782, 0.9743801750309414],\n",
       " [783, 0.937346702037999],\n",
       " [784, 0.965447299761743],\n",
       " [785, 0.9646690824161294],\n",
       " [786, 0.9804262668200274],\n",
       " [787, 0.9755498443182429],\n",
       " [788, 0.9965294797779656],\n",
       " [789, 0.9840121894055648],\n",
       " [790, 0.9819260220255964],\n",
       " [791, 0.9380393112996516],\n",
       " [792, 0.9907283548628832],\n",
       " [793, 0.9400198278324091],\n",
       " [794, 0.9661621869244978],\n",
       " [795, 0.9971783080980551],\n",
       " [796, 0.9713658029190206],\n",
       " [797, 0.9885127158265447],\n",
       " [798, 0.9771325555197151],\n",
       " [799, 0.9682122781405657],\n",
       " [800, 0.9910746679737854],\n",
       " [801, 0.9329461594644876],\n",
       " [802, 0.042437142960919244],\n",
       " [803, 0.03330849960389546],\n",
       " [804, 0.9741896531234885],\n",
       " [805, 0.981740170242888],\n",
       " [806, 0.9443940172061804],\n",
       " [807, 0.9643942688947157],\n",
       " [808, 0.9361933804027082],\n",
       " [809, 0.9598229588787696],\n",
       " [810, 0.982948398771376],\n",
       " [811, 0.9693996253538185],\n",
       " [812, 0.9828190273535911],\n",
       " [813, 0.9871787599643799],\n",
       " [814, 0.9853010535891067],\n",
       " [815, 0.9650420221765952],\n",
       " [816, 0.9259674181798644],\n",
       " [817, 0.9611143113519853],\n",
       " [818, 0.9606113622988],\n",
       " [819, 0.9551744065150346],\n",
       " [820, 0.9619269651210024],\n",
       " [821, 0.9718058149225604],\n",
       " [822, 0.9758030342644841],\n",
       " [823, 0.9932885215998977],\n",
       " [824, 0.9449174109647002],\n",
       " [825, 0.9882888323897775],\n",
       " [826, 0.9861155416614173],\n",
       " [827, 0.9926335859436136],\n",
       " [828, 0.9651362183693751],\n",
       " [829, 0.920214306294615],\n",
       " [830, 0.9229787716946184],\n",
       " [831, 0.985652350950127],\n",
       " [832, 0.9433624467800127],\n",
       " [833, 0.943284203113735],\n",
       " [834, 0.016314814626440192],\n",
       " [835, 0.9785347698750314],\n",
       " [836, 0.10736975245598594],\n",
       " [837, 0.9689462797249684],\n",
       " [838, 0.9881387130861047],\n",
       " [839, 0.9832999152577284],\n",
       " [840, 0.07641085419086949],\n",
       " [841, 0.967882097380011],\n",
       " [842, 0.9521885504391517],\n",
       " [843, 0.9806574951367789],\n",
       " [844, 0.9837020265482154],\n",
       " [845, 0.2376144854757345],\n",
       " [846, 0.9854160597399974],\n",
       " [847, 0.9819819538564202],\n",
       " [848, 0.060996357828758424],\n",
       " [849, 0.9521885504391517],\n",
       " [850, 0.938056264248799],\n",
       " [851, 0.9660074817370535],\n",
       " [852, 0.9847139199191063],\n",
       " [853, 0.9758936455463197],\n",
       " [854, 0.9794830647725387],\n",
       " [855, 0.9871787599643799],\n",
       " [856, 0.9074138826577988],\n",
       " [857, 0.938851932576879],\n",
       " [858, 0.9712008699612461],\n",
       " [859, 0.9267986783690869],\n",
       " [860, 0.9735071368571142],\n",
       " [861, 0.9573686100052452],\n",
       " [862, 0.7678998827460702],\n",
       " [863, 0.9265910181389292],\n",
       " [864, 0.9756999264081546],\n",
       " [865, 0.981576580262972],\n",
       " [866, 0.9911475886298735],\n",
       " [867, 0.9435989436474165],\n",
       " [868, 0.20144358357679418],\n",
       " [869, 0.9754277733141637],\n",
       " [870, 0.9303682095503601],\n",
       " [871, 0.985237084558229],\n",
       " [872, 0.9551814924522892],\n",
       " [873, 0.987574758890324],\n",
       " [874, 0.9628126610158528],\n",
       " [875, 0.9670622235224636],\n",
       " [876, 0.9489191236204036],\n",
       " [877, 0.1847140312107609],\n",
       " [878, 0.9870348404508767],\n",
       " [879, 0.9848620172128894],\n",
       " [880, 0.9756878611064121],\n",
       " [881, 0.9894938118348705],\n",
       " [882, 0.6922191874916593],\n",
       " [883, 0.9702167817841723],\n",
       " [884, 0.9784807151780854],\n",
       " [885, 0.9472028337968853],\n",
       " [886, 0.9694928104256805],\n",
       " [887, 0.5153692808860911],\n",
       " [888, 0.9730612832457091],\n",
       " [889, 0.9816481209024263],\n",
       " [890, 0.3526573944009536],\n",
       " [891, 0.9697656794820091],\n",
       " [892, 0.9337131274538643],\n",
       " [893, 0.9666254131376023],\n",
       " [894, 0.9655008239892556],\n",
       " [895, 0.9673379823756524],\n",
       " [896, 0.984654848562328],\n",
       " [897, 0.9403512607265495],\n",
       " [898, 0.9871787599643799],\n",
       " [899, 0.9838050688994446],\n",
       " [900, 0.925417690934171],\n",
       " [901, 0.9779111644979602],\n",
       " [902, 0.9810253055131003],\n",
       " [903, 0.9831386174920281],\n",
       " [904, 0.975793777500482],\n",
       " [905, 0.9913375022291548],\n",
       " [906, 0.9681427933703803],\n",
       " [907, 0.9379721214586869],\n",
       " [908, 0.6892345671352395],\n",
       " [909, 0.9529842247186094],\n",
       " [910, 0.971556538863498],\n",
       " [911, 0.9838942071792266],\n",
       " [912, 0.7460394365829709],\n",
       " [913, 0.9778196269318341],\n",
       " [914, 0.9598227463507616],\n",
       " [915, 0.9466998935304213],\n",
       " [916, 0.949588468164411],\n",
       " [917, 0.9777046375653141],\n",
       " [918, 0.9770277845633526],\n",
       " [919, 0.9734597948952045],\n",
       " [920, 0.9695367883106334],\n",
       " [921, 0.9654170959088905],\n",
       " [922, 0.10257461858288215],\n",
       " [923, 0.8788662427006871],\n",
       " [924, 0.028232277809186006],\n",
       " [925, 0.9902859134902787],\n",
       " [926, 0.9859839708580914],\n",
       " [927, 0.9927581997121916],\n",
       " [928, 0.04307363146722479],\n",
       " [929, 0.9078922443626883],\n",
       " [930, 0.9842828104357256],\n",
       " [931, 0.9855612565539467],\n",
       " [932, 0.9632653733472992],\n",
       " [933, 0.9904037954130951],\n",
       " [934, 0.977811974391655],\n",
       " [935, 0.9814784190148346],\n",
       " [936, 0.9838251947079112],\n",
       " [937, 0.9719858615989425],\n",
       " [938, 0.9839456444716016],\n",
       " [939, 0.9670350469704972],\n",
       " [940, 0.9383056255459731],\n",
       " [941, 0.9699849767438163],\n",
       " [942, 0.962283095527674],\n",
       " [943, 0.917530471926132],\n",
       " [944, 0.9676900029969139],\n",
       " [945, 0.02847517913871016],\n",
       " [946, 0.3031103838197082],\n",
       " [947, 0.9838942071792266],\n",
       " [948, 0.08912406742632269],\n",
       " [949, 0.9896562251502775],\n",
       " [950, 0.9857196087692333],\n",
       " [951, 0.9703013749346457],\n",
       " [952, 0.9630955424226211],\n",
       " [953, 0.9619269651210024],\n",
       " [954, 0.9104136991465325],\n",
       " [955, 0.9549659363981092],\n",
       " [956, 0.7439364021776047],\n",
       " [957, 0.9773098267315241],\n",
       " [958, 0.9867199197423396],\n",
       " [959, 0.9807628235288819],\n",
       " [960, 0.9793696106138667],\n",
       " [961, 0.9893968414495738],\n",
       " [962, 0.9605366589279111],\n",
       " [963, 0.9703717980235993],\n",
       " [964, 0.9827423034444646],\n",
       " [965, 0.9906032981439336],\n",
       " [966, 0.9704051770543739],\n",
       " [967, 0.9723391576128614],\n",
       " [968, 0.9642954437033208],\n",
       " [969, 0.9860315665497099],\n",
       " [970, 0.9575489012418802],\n",
       " [971, 0.971304188119351],\n",
       " [972, 0.9521885504391517],\n",
       " [973, 0.9813936831565145],\n",
       " [974, 0.9893968414495738],\n",
       " [975, 0.9924696495180175],\n",
       " [976, 0.934612703917738],\n",
       " [977, 0.9650226043144476],\n",
       " [978, 0.9599093517914484],\n",
       " [979, 0.9245851981941766],\n",
       " [980, 0.972889074279473],\n",
       " [981, 0.9933513451043955],\n",
       " [982, 0.9901256090809479],\n",
       " [983, 0.9852966516481868],\n",
       " [984, 0.9816838085922436],\n",
       " [985, 0.9550390949452222],\n",
       " [986, 0.12706734823723964],\n",
       " [987, 0.9695367883106334],\n",
       " [988, 0.7322859122365392],\n",
       " [989, 0.9819224025272778],\n",
       " [990, 0.054806429498583144],\n",
       " [991, 0.9837303028263576],\n",
       " [992, 0.9790019353976126],\n",
       " [993, 0.9866195007175715],\n",
       " [994, 0.9893968414495738],\n",
       " [995, 0.9836789953272125],\n",
       " [996, 0.935574581511123],\n",
       " [997, 0.9727900971547125],\n",
       " [998, 0.9885864472091376],\n",
       " [999, 0.9653077268279601],\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_output('combined_prob_and_log_reg_no_quadgram.csv',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
